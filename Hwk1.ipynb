{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/uciml/pima-indians-diabetes-database - Download the indian diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Import relevant commands for numpy, pandas, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn import cluster\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Using the appropriate pandas function, read the diabetes.csv into a dataframe. Pay good attention to the necessary arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a6d1dd6feb87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'feature_names'"
     ]
    }
   ],
   "source": [
    "data = read_csv('diabetes.csv', sep=\",\")\n",
    "data.feature_names\n",
    "print(data)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.use naivebayes, logistic regression and 3-nn classifiers (library) to train on the training sets and \n",
    "compute training and validation errors for each fold (see the diabetes_10fold_train_val.zip file, XT01...XT10: training sets, XV01....XV10: corresponding validation sets). The target label is Outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features\n",
      "     Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0         83             66             23       50  32.2   \n",
      "1         99             54             28       83  34.0   \n",
      "2          0             74             20       23  27.7   \n",
      "3        100              0              0        0  30.0   \n",
      "4        106             70              0        0  34.2   \n",
      "..       ...            ...            ...      ...   ...   \n",
      "687      100             68             25       71  38.5   \n",
      "688      132             78              0        0  32.4   \n",
      "689      151             90             46        0  42.1   \n",
      "690      173             78             32      265  46.5   \n",
      "691      107             76              0        0  45.3   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  \n",
      "0                       0.497   22  \n",
      "1                       0.499   30  \n",
      "2                       0.299   21  \n",
      "3                       0.484   32  \n",
      "4                       0.251   52  \n",
      "..                        ...  ...  \n",
      "687                     0.324   26  \n",
      "688                     0.393   21  \n",
      "689                     0.371   21  \n",
      "690                     1.159   58  \n",
      "691                     0.686   24  \n",
      "\n",
      "[692 rows x 7 columns]\n",
      "Label\n",
      "0     1\n",
      "1     1\n",
      "2     0\n",
      "3     0\n",
      "4     1\n",
      "     ..\n",
      "71    0\n",
      "72    0\n",
      "73    1\n",
      "74    0\n",
      "75    0\n",
      "Name: Outcome, Length: 76, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [692, 76]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-6104c1cf750e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#Train the model using the training sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [692, 76]"
     ]
    }
   ],
   "source": [
    "    \n",
    "    \n",
    "    #Create a Gaussian Classifier\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    #Import scikit-learn metrics module for accuracy calculation\n",
    "    from sklearn import metrics\n",
    "\n",
    "    trainingSet = '/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XT'+file_number[i]+'.csv'\n",
    "    XT = read_csv(trainingSet, sep=\",\")\n",
    "    validationSet = '/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XV'+file_number[i]+'.csv'\n",
    "    VT = read_csv(validationSet, sep=\",\")\n",
    "    \n",
    "    # all features in x train\n",
    "    X_train = XT.iloc[:,1:8]\n",
    "    print(\"Features\")\n",
    "    print(X_train)\n",
    "    # outcome or label in Y train\n",
    "    Y_train = VT.iloc[:,8]\n",
    "    print(\"Label\")\n",
    "    print(Y_train)\n",
    "    \n",
    "    #Train the model using the training sets\n",
    "    gnb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set 01:  0.7894736842105263\n",
      "Error :  0.21052631578947367\n",
      "Accuracy for training set 02:  0.7142857142857143\n",
      "Error :  0.2857142857142857\n",
      "Accuracy for training set 03:  0.7012987012987013\n",
      "Error :  0.2987012987012987\n",
      "Accuracy for training set 04:  0.8311688311688312\n",
      "Error :  0.16883116883116878\n",
      "Accuracy for training set 05:  0.7792207792207793\n",
      "Error :  0.22077922077922074\n",
      "Accuracy for training set 06:  0.7402597402597403\n",
      "Error :  0.2597402597402597\n",
      "Accuracy for training set 07:  0.7792207792207793\n",
      "Error :  0.22077922077922074\n",
      "Accuracy for training set 08:  0.7272727272727273\n",
      "Error :  0.2727272727272727\n",
      "Accuracy for training set 09:  0.8181818181818182\n",
      "Error :  0.18181818181818177\n",
      "Accuracy for training set 10:  0.6973684210526315\n",
      "Error :  0.3026315789473685\n"
     ]
    }
   ],
   "source": [
    "# # Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "# import first training set\n",
    "t1 = read_csv('/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XT01.csv', sep=\",\")\n",
    "v1 = read_csv('/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XV01.csv', sep=\",\")\n",
    "\n",
    "# #creating labelEncoder\n",
    "# le = preprocessing.LabelEncoder()\n",
    "\n",
    "# # feature1\n",
    "# # Converting string labels into numbers.\n",
    "# pregnancies_encoded=le.fit_transform((t1.iloc[:,0]))\n",
    "# print (\"Pregnancies:\",pregnancies_encoded)\n",
    "\n",
    "# # feature2\n",
    "# # Converting string labels into numbers.\n",
    "# glucose_encoded=le.fit_transform((t1.iloc[:,1]))\n",
    "# print (\"Glucose:\",glucose_encoded)\n",
    "\n",
    "# # feature3\n",
    "# # Converting string labels into numbers.\n",
    "# bp_encoded=le.fit_transform((t1.iloc[:,2]))\n",
    "# print (\"BloodPressure:\",bp_encoded)\n",
    "\n",
    "# # feature4\n",
    "# # Converting string labels into numbers.\n",
    "# skinthickness_encoded=le.fit_transform((t1.iloc[:,3]))\n",
    "# print (\"SkinThickness:\",skinthickness_encoded)\n",
    "\n",
    "# # feature5\n",
    "# # Converting string labels into numbers.\n",
    "# insulin_encoded=le.fit_transform((t1.iloc[:,4]))\n",
    "# print (\"Insulin:\",insulin_encoded)\n",
    "\n",
    "# # feature6\n",
    "# # Converting string labels into numbers.\n",
    "# bmi_encoded=le.fit_transform((t1.iloc[:,5]))\n",
    "# print (\"BMI:\",bmi_encoded)\n",
    "\n",
    "# # feature7\n",
    "# # Converting string labels into numbers.\n",
    "# pedigreeFunction_encoded=le.fit_transform((t1.iloc[:,6]))\n",
    "# print (\"DiabetesPedigreeFunction:\",pedigreeFunction_encoded)\n",
    "\n",
    "# # feature8\n",
    "# # Converting string labels into numbers.\n",
    "# age_encoded=le.fit_transform((t1.iloc[:,7]))\n",
    "# print (\"Age:\",age_encoded)\n",
    "\n",
    "# # outcome\n",
    "# label=le.fit_transform((t1.iloc[:,8]))\n",
    "# print (\"Outcome:\",label)\n",
    "\n",
    "# #Combinig weather and temp into single listof tuples\n",
    "# features=list(zip(pregnancies_encoded, glucose_encoded, bp_encoded, skinthickness_encoded, insulin_encoded, bmi_encoded, pedigreeFunction_encoded, age_encoded))\n",
    "# print (features)\n",
    "\n",
    "# #Create a Gaussian Classifier\n",
    "# model = GaussianNB()\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# model.fit(features,label)\n",
    "\n",
    "# #Predict Output\n",
    "# predicted= model.predict([[7,178,84,0,0,39.9,0.331,41]]) \n",
    "# print (\"Predicted Value:\", predicted)\n",
    "# predicted2= model.predict([[6,98,58,33,190,34,0.43,43]])\n",
    "# print (\"Predicted Value2:\", predicted2)\n",
    "\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# # all features in x train\n",
    "# X_train = t1.iloc[:,1:8]\n",
    "# print(\"Features\")\n",
    "# print(X_train)\n",
    "# # outcome or label in Y train\n",
    "# Y_train = t1.iloc[:,8]\n",
    "# print(\"Label\")\n",
    "# print(Y_train)\n",
    "\n",
    "# #Train the model using the training sets\n",
    "# gnb.fit(X_train, Y_train)\n",
    "\n",
    "# #Predict the response for test dataset\n",
    "# y_pred = gnb.predict(v1.iloc[:,1:8])\n",
    "# print(y_pred)\n",
    "\n",
    "# #Import scikit-learn metrics module for accuracy calculation\n",
    "# from sklearn import metrics\n",
    "# accuracy = metrics.accuracy_score(v1.iloc[:,8], y_pred)\n",
    "# # Model Accuracy, how often is the classifier correct?\n",
    "# print(\"Accuracy:\",accuracy)\n",
    "# print(\"Error:\",1- accuracy)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "VT_features = []\n",
    "VT_label = []\n",
    "\n",
    "\n",
    "file_number = ['01','02','03','04','05','06','07','08','09','10']\n",
    "# loop here to calculate the error for each training set\n",
    "for i in range(len(file_number)):\n",
    "#     print(file_number[i])\n",
    "    trainingSet = '/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XT'+file_number[i]+'.csv'\n",
    "    XT = read_csv(trainingSet, sep=\",\")\n",
    "    validationSet = '/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XV'+file_number[i]+'.csv'\n",
    "    VT = read_csv(validationSet, sep=\",\")\n",
    "    \n",
    "    # all features in x train\n",
    "    X_train =  XT.iloc[:,1:8]\n",
    "#     print(\"Features\")\n",
    "#     print(X_train)\n",
    "    # outcome or label in Y train\n",
    "    Y_train = XT.iloc[:,8]\n",
    "#     print(\"Label\")\n",
    "#     print(Y_train)\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    gnb.fit(X_train, Y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    VT_features =  VT.iloc[:,1:8]\n",
    "    y_pred = gnb.predict(VT_features)\n",
    "#     print(y_pred)\n",
    "\n",
    "    VT_label =  VT.iloc[:,8]\n",
    "    accuracy = metrics.accuracy_score(VT_label, y_pred)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy for training set \"+ file_number[i]+ \": \" ,accuracy)\n",
    "    print(\"Error : \",1- accuracy)\n",
    "\n",
    "\n",
    "# for name, model in models:\n",
    "# \tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# # \tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "#     t1 = read_csv('/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XT01.csv', sep=\",\")\n",
    "#     v1 = read_csv('/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XV01.csv', sep=\",\")\n",
    "#     gnb.fit(X_train, Y_train)\n",
    "# \tresults.append(cv_results)\n",
    "# \tnames.append(name)\n",
    "# \tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "\n",
    "\n",
    "# trying new\n",
    "# Spot Check Algorithms  //https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "# models = []\n",
    "# models.append(('LR', LogisticRegression())\n",
    "# models.append(('KNN', KNeighborsClassifier()))\n",
    "# models.append(('NB', GaussianNB()))\n",
    "# # evaluate each model in turn\n",
    "# results = []\n",
    "# names = []\n",
    "# for name, model in models:\n",
    "# \tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# \tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "# \tresults.append(cv_results)\n",
    "# \tnames.append(name)\n",
    "# \tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.is the error of naive bayes <0.2 with confidence 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.have  naive bayes and knn the same error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.do the three classifiers have different errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
