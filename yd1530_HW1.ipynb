{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/uciml/pima-indians-diabetes-database - Download the indian diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Import relevant commands for numpy, pandas, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn import cluster\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Using the appropriate pandas function, read the diabetes.csv into a dataframe. Pay good attention to the necessary arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              5       95             72             33        0  37.7   \n",
      "1              0      131              0              0        0  43.2   \n",
      "2              2      112             66             22        0  25.0   \n",
      "3              3      113             44             13        0  22.4   \n",
      "4              2       74              0              0        0   0.0   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           13      126             90              0        0  43.4   \n",
      "764            4      129             86             20      270  35.1   \n",
      "765            1       79             75             30        0  32.0   \n",
      "766            1        0             48             20        0  24.7   \n",
      "767            7       62             78              0        0  32.6   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.370   27        0  \n",
      "1                       0.270   26        1  \n",
      "2                       0.307   24        0  \n",
      "3                       0.140   22        0  \n",
      "4                       0.102   22        0  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.583   42        1  \n",
      "764                     0.231   23        0  \n",
      "765                     0.396   22        0  \n",
      "766                     0.140   22        0  \n",
      "767                     0.391   41        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data = read_csv('diabetes.csv', sep=\",\")\n",
    "# Calling DataFrame constructor \n",
    "df = DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.use naivebayes, logistic regression and 3-nn classifiers (library) to train on the training sets and \n",
    "compute training and validation errors for each fold (see the diabetes_10fold_train_val.zip file, XT01...XT10: training sets, XV01....XV10: corresponding validation sets). The target label is Outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Error for validation set and training set 01: \n",
      "\n",
      "NB: Validation Error:  0.21052631578947367 ; Training Error:  0.24566473988439308\n",
      "LR: Validation Error:  0.23684210526315785 ; Training Error:  0.2225433526011561\n",
      "NN: Validation Error:  0.25 ; Training Error:  0.14306358381502893\n",
      "\n",
      " Error for validation set and training set 02: \n",
      "\n",
      "NB: Validation Error:  0.2857142857142857 ; Training Error:  0.23733719247467433\n",
      "LR: Validation Error:  0.2597402597402597 ; Training Error:  0.22141823444283648\n",
      "NN: Validation Error:  0.4155844155844156 ; Training Error:  0.14905933429811868\n",
      "\n",
      " Error for validation set and training set 03: \n",
      "\n",
      "NB: Validation Error:  0.2987012987012987 ; Training Error:  0.23010130246020255\n",
      "LR: Validation Error:  0.2727272727272727 ; Training Error:  0.2098408104196816\n",
      "NN: Validation Error:  0.2987012987012987 ; Training Error:  0.1432706222865412\n",
      "\n",
      " Error for validation set and training set 04: \n",
      "\n",
      "NB: Validation Error:  0.16883116883116878 ; Training Error:  0.24312590448625182\n",
      "LR: Validation Error:  0.16883116883116878 ; Training Error:  0.23299565846599135\n",
      "NN: Validation Error:  0.16883116883116878 ; Training Error:  0.15774240231548475\n",
      "\n",
      " Error for validation set and training set 05: \n",
      "\n",
      "NB: Validation Error:  0.22077922077922074 ; Training Error:  0.2489146164978292\n",
      "LR: Validation Error:  0.18181818181818177 ; Training Error:  0.22720694645441386\n",
      "NN: Validation Error:  0.24675324675324672 ; Training Error:  0.1432706222865412\n",
      "\n",
      " Error for validation set and training set 06: \n",
      "\n",
      "NB: Validation Error:  0.2597402597402597 ; Training Error:  0.23444283646888564\n",
      "LR: Validation Error:  0.22077922077922074 ; Training Error:  0.22286541244573077\n",
      "NN: Validation Error:  0.35064935064935066 ; Training Error:  0.14761215629522428\n",
      "\n",
      " Error for validation set and training set 07: \n",
      "\n",
      "NB: Validation Error:  0.22077922077922074 ; Training Error:  0.24023154848046313\n",
      "LR: Validation Error:  0.23376623376623373 ; Training Error:  0.21997105643994208\n",
      "NN: Validation Error:  0.2597402597402597 ; Training Error:  0.16063675832127355\n",
      "\n",
      " Error for validation set and training set 08: \n",
      "\n",
      "NB: Validation Error:  0.2727272727272727 ; Training Error:  0.23299565846599135\n",
      "LR: Validation Error:  0.2597402597402597 ; Training Error:  0.2185238784370478\n",
      "NN: Validation Error:  0.33766233766233766 ; Training Error:  0.14905933429811868\n",
      "\n",
      " Error for validation set and training set 09: \n",
      "\n",
      "NB: Validation Error:  0.18181818181818177 ; Training Error:  0.24167872648335742\n",
      "LR: Validation Error:  0.19480519480519476 ; Training Error:  0.22286541244573077\n",
      "NN: Validation Error:  0.3246753246753247 ; Training Error:  0.1432706222865412\n",
      "\n",
      " Error for validation set and training set 10: \n",
      "\n",
      "NB: Validation Error:  0.3026315789473685 ; Training Error:  0.23121387283236994\n",
      "LR: Validation Error:  0.2894736842105263 ; Training Error:  0.21820809248554918\n",
      "NN: Validation Error:  0.368421052631579 ; Training Error:  0.14306358381502893\n",
      "\n",
      "Final NB error:  0.24222488038277512\n",
      "Final LR error:  0.27117224880382773\n",
      "Final NN error:  0.279066985645933\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Create a logistic regression classifier\n",
    "lrclassifier = LogisticRegression(random_state=0, max_iter=1000)\n",
    "\n",
    "#Create a knn classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#find the mean at the end\n",
    "mean_nb = 0\n",
    "\n",
    "# create a list to store the file numbers\n",
    "file_number = ['01','02','03','04','05','06','07','08','09','10']\n",
    "\n",
    "# loop here to calculate the error for each training set\n",
    "for i in file_number:\n",
    "    \n",
    "    trainingSet = '/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XT'+i+'.csv'\n",
    "    XT = read_csv(trainingSet, sep=\",\")\n",
    "    validationSet = '/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XV'+i+'.csv'\n",
    "    VT = read_csv(validationSet, sep=\",\")\n",
    "    \n",
    "    # all features in x train\n",
    "    X_train =  XT.iloc[:,1:8]\n",
    "    # outcome or label in Y train\n",
    "    Y_train = XT.iloc[:,8]\n",
    "\n",
    "    #Train the all 3 models using the training sets\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    logistic = lrclassifier.fit(X_train, Y_train)\n",
    "    fit   = knn.fit(X_train, Y_train)\n",
    "\n",
    "    #predict the response for training data itself\n",
    "    XT_features =  XT.iloc[:,1:8]\n",
    "    y_pred_nb_train = gnb.predict(XT_features)\n",
    "    y_pred_nn_train = fit.predict(XT_features)\n",
    "    y_pred_lr_train = logistic.predict(XT_features)\n",
    "    XT_label_train =  XT.iloc[:,8]\n",
    "    accuracy_nb_train = metrics.accuracy_score(XT_label_train, y_pred_nb_train)\n",
    "    accuracy_lr_train = metrics.accuracy_score(XT_label_train, y_pred_lr_train)\n",
    "    accuracy_nn_train = metrics.accuracy_score(XT_label_train, y_pred_nn_train)\n",
    "    \n",
    "    \n",
    "    #Predict the response for validation dataset\n",
    "    VT_features =  VT.iloc[:,1:8]\n",
    "    y_pred_nb = gnb.predict(VT_features)\n",
    "    y_pred_nn = fit.predict(VT_features)\n",
    "    y_pred_lr = logistic.predict(VT_features)\n",
    "    VT_label =  VT.iloc[:,8]\n",
    "    accuracy_nb = metrics.accuracy_score(VT_label, y_pred_nb)\n",
    "    accuracy_lr = metrics.accuracy_score(VT_label, y_pred_lr)\n",
    "    accuracy_nn = metrics.accuracy_score(VT_label, y_pred_nn)\n",
    "\n",
    "    mean_nb = mean_nb + (1 - accuracy_nb)\n",
    "    mean_lr = mean_nb + (1 - accuracy_lr)\n",
    "    mean_nn = mean_nb + (1 - accuracy_nn)\n",
    "\n",
    "    # Model Accuracy and Error\n",
    "    print(\"\\n Error for validation set and training set \"+ i+ \": \\n\")\n",
    "    print(\"NB: Validation Error: \"  , 1 - accuracy_nb, \"; Training Error: \", 1 - accuracy_nb_train)\n",
    "    print(\"LR: Validation Error: \"  , 1 - accuracy_lr, \"; Training Error: \", 1 - accuracy_lr_train)\n",
    "    print(\"NN: Validation Error: \"  , 1 - accuracy_nn, \"; Training Error: \", 1 - accuracy_nn_train)\n",
    "\n",
    "# calculating average error from 10 sets\n",
    "print(\"\\nFinal NB error: \",mean_nb/10)\n",
    "print(\"Final LR error: \",mean_lr/10)\n",
    "print(\"Final NN error: \",mean_nn/10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.is the error of naive bayes <0.2 with confidence 0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.have  naive bayes and knn the same error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.do the three classifiers have different errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
