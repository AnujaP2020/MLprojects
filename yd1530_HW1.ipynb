{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/uciml/pima-indians-diabetes-database - Download the indian diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Import relevant commands for numpy, pandas, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn import cluster\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "folds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Using the appropriate pandas function, read the diabetes.csv into a dataframe. Pay good attention to the necessary arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              5       95             72             33        0  37.7   \n",
      "1              0      131              0              0        0  43.2   \n",
      "2              2      112             66             22        0  25.0   \n",
      "3              3      113             44             13        0  22.4   \n",
      "4              2       74              0              0        0   0.0   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           13      126             90              0        0  43.4   \n",
      "764            4      129             86             20      270  35.1   \n",
      "765            1       79             75             30        0  32.0   \n",
      "766            1        0             48             20        0  24.7   \n",
      "767            7       62             78              0        0  32.6   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.370   27        0  \n",
      "1                       0.270   26        1  \n",
      "2                       0.307   24        0  \n",
      "3                       0.140   22        0  \n",
      "4                       0.102   22        0  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.583   42        1  \n",
      "764                     0.231   23        0  \n",
      "765                     0.396   22        0  \n",
      "766                     0.140   22        0  \n",
      "767                     0.391   41        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data = read_csv('diabetes.csv', sep=\",\")\n",
    "# Calling DataFrame constructor \n",
    "df = DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.use naivebayes, logistic regression and 3-nn classifiers (library) to train on the training sets and \n",
    "compute training and validation errors for each fold (see the diabetes_10fold_train_val.zip file, XT01...XT10: training sets, XV01....XV10: corresponding validation sets). The target label is Outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error for validation set and training set 01: \n",
      "\n",
      "NB: Validation Error:  0.21052631578947367 ; Training Error:  0.24566473988439308\n",
      "LR: Validation Error:  0.23684210526315785 ; Training Error:  0.2225433526011561\n",
      "KNN: Validation Error:  0.25 ; Training Error:  0.14306358381502893\n",
      "\n",
      "Error for validation set and training set 02: \n",
      "\n",
      "NB: Validation Error:  0.2857142857142857 ; Training Error:  0.23733719247467433\n",
      "LR: Validation Error:  0.2597402597402597 ; Training Error:  0.22141823444283648\n",
      "KNN: Validation Error:  0.4155844155844156 ; Training Error:  0.14905933429811868\n",
      "\n",
      "Error for validation set and training set 03: \n",
      "\n",
      "NB: Validation Error:  0.2987012987012987 ; Training Error:  0.23010130246020255\n",
      "LR: Validation Error:  0.2727272727272727 ; Training Error:  0.2098408104196816\n",
      "KNN: Validation Error:  0.2987012987012987 ; Training Error:  0.1432706222865412\n",
      "\n",
      "Error for validation set and training set 04: \n",
      "\n",
      "NB: Validation Error:  0.16883116883116878 ; Training Error:  0.24312590448625182\n",
      "LR: Validation Error:  0.16883116883116878 ; Training Error:  0.23299565846599135\n",
      "KNN: Validation Error:  0.16883116883116878 ; Training Error:  0.15774240231548475\n",
      "\n",
      "Error for validation set and training set 05: \n",
      "\n",
      "NB: Validation Error:  0.22077922077922074 ; Training Error:  0.2489146164978292\n",
      "LR: Validation Error:  0.18181818181818177 ; Training Error:  0.22720694645441386\n",
      "KNN: Validation Error:  0.24675324675324672 ; Training Error:  0.1432706222865412\n",
      "\n",
      "Error for validation set and training set 06: \n",
      "\n",
      "NB: Validation Error:  0.2597402597402597 ; Training Error:  0.23444283646888564\n",
      "LR: Validation Error:  0.22077922077922074 ; Training Error:  0.22286541244573077\n",
      "KNN: Validation Error:  0.35064935064935066 ; Training Error:  0.14761215629522428\n",
      "\n",
      "Error for validation set and training set 07: \n",
      "\n",
      "NB: Validation Error:  0.22077922077922074 ; Training Error:  0.24023154848046313\n",
      "LR: Validation Error:  0.23376623376623373 ; Training Error:  0.21997105643994208\n",
      "KNN: Validation Error:  0.2597402597402597 ; Training Error:  0.16063675832127355\n",
      "\n",
      "Error for validation set and training set 08: \n",
      "\n",
      "NB: Validation Error:  0.2727272727272727 ; Training Error:  0.23299565846599135\n",
      "LR: Validation Error:  0.2597402597402597 ; Training Error:  0.2185238784370478\n",
      "KNN: Validation Error:  0.33766233766233766 ; Training Error:  0.14905933429811868\n",
      "\n",
      "Error for validation set and training set 09: \n",
      "\n",
      "NB: Validation Error:  0.18181818181818177 ; Training Error:  0.24167872648335742\n",
      "LR: Validation Error:  0.19480519480519476 ; Training Error:  0.22286541244573077\n",
      "KNN: Validation Error:  0.3246753246753247 ; Training Error:  0.1432706222865412\n",
      "\n",
      "Error for validation set and training set 10: \n",
      "\n",
      "NB: Validation Error:  0.3026315789473685 ; Training Error:  0.23121387283236994\n",
      "LR: Validation Error:  0.2894736842105263 ; Training Error:  0.21820809248554918\n",
      "KNN: Validation Error:  0.368421052631579 ; Training Error:  0.14306358381502893\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Create a logistic regression classifier\n",
    "lrclassifier = LogisticRegression(random_state=0, max_iter=1000)\n",
    "\n",
    "#Create a knn classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#find the mean at the end\n",
    "mean_nb = 0\n",
    "mean_lr = 0\n",
    "mean_nn = 0\n",
    "\n",
    "# create a list to store the file numbers\n",
    "file_number = ['01','02','03','04','05','06','07','08','09','10']\n",
    "validation_errors_nb = []\n",
    "validation_errors_lr = []\n",
    "validation_errors_nn = []\n",
    "\n",
    "\n",
    "# loop here to calculate the error for each training set\n",
    "for i in file_number:\n",
    "    \n",
    "    trainingSet = '/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XT'+i+'.csv'\n",
    "    XT = read_csv(trainingSet, sep=\",\")\n",
    "    validationSet = '/media/anuja/study/Anuja/MS/CS_697A(ML)/hw1/diabetes_10fold_train_val/XV'+i+'.csv'\n",
    "    VT = read_csv(validationSet, sep=\",\")\n",
    "    \n",
    "    # all features in x train\n",
    "    X_train =  XT.iloc[:,1:8]\n",
    "    # outcome or label in Y train\n",
    "    Y_train = XT.iloc[:,8]\n",
    "\n",
    "    #Train the all 3 models using the training sets\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    logistic = lrclassifier.fit(X_train, Y_train)\n",
    "    fit   = knn.fit(X_train, Y_train)\n",
    "\n",
    "    #predict the response for training data itself\n",
    "    XT_features =  XT.iloc[:,1:8]\n",
    "    y_pred_nb_train = gnb.predict(XT_features)\n",
    "    y_pred_nn_train = fit.predict(XT_features)\n",
    "    y_pred_lr_train = logistic.predict(XT_features)\n",
    "    XT_label_train =  XT.iloc[:,8]\n",
    "    accuracy_nb_train = metrics.accuracy_score(XT_label_train, y_pred_nb_train)\n",
    "    accuracy_lr_train = metrics.accuracy_score(XT_label_train, y_pred_lr_train)\n",
    "    accuracy_nn_train = metrics.accuracy_score(XT_label_train, y_pred_nn_train)\n",
    "    \n",
    "    \n",
    "    #Predict the response for validation dataset\n",
    "    VT_features =  VT.iloc[:,1:8]\n",
    "    y_pred_nb = gnb.predict(VT_features)\n",
    "    y_pred_nn = fit.predict(VT_features)\n",
    "    y_pred_lr = logistic.predict(VT_features)\n",
    "    VT_label =  VT.iloc[:,8]\n",
    "    accuracy_nb = metrics.accuracy_score(VT_label, y_pred_nb)\n",
    "    accuracy_lr = metrics.accuracy_score(VT_label, y_pred_lr)\n",
    "    accuracy_nn = metrics.accuracy_score(VT_label, y_pred_nn)\n",
    "    \n",
    "    validation_errors_nb.append(1- accuracy_nb);\n",
    "    validation_errors_lr.append(1- accuracy_lr);\n",
    "    validation_errors_nn.append(1- accuracy_nn);\n",
    "\n",
    "\n",
    "    mean_nb = mean_nb + (1 - accuracy_nb)\n",
    "    mean_lr = mean_lr + (1 - accuracy_lr)\n",
    "    mean_nn = mean_nn + (1 - accuracy_nn)\n",
    "\n",
    "    # Model Accuracy and Error\n",
    "    print(\"\\nError for validation set and training set \"+ i+ \": \\n\")\n",
    "    print(\"NB: Validation Error: \"  , 1 - accuracy_nb, \"; Training Error: \", 1 - accuracy_nb_train)\n",
    "    print(\"LR: Validation Error: \"  , 1 - accuracy_lr, \"; Training Error: \", 1 - accuracy_lr_train)\n",
    "    print(\"KNN: Validation Error: \"  , 1 - accuracy_nn, \"; Training Error: \", 1 - accuracy_nn_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NB validation error:  0.24222488038277512\n",
      "Mean LR validation error:  0.23185235816814762\n",
      "Mean NN validation error:  0.30210184552289815\n",
      "\n",
      "Standard deviation for NB classifier:  0.045746372142671576\n",
      "Standard deviation for LR classifier:  0.03813817280954714\n",
      "Standard deviation for NN classifier:  0.06837595511784197\n",
      "\n",
      "Standard error for NB classifier:  2.9188499477356338\n",
      "Standard error for LR classifier:  2.6410809233524737\n",
      "Standard error for NN classifier:  4.722045704554598\n"
     ]
    }
   ],
   "source": [
    "# now calculate the standard error and confidence\n",
    "\n",
    "# calculating average of validation error from 10 sets\n",
    "mean_validation_error_nb = mean_nb/folds;\n",
    "mean_validation_error_lr = mean_lr/folds;\n",
    "mean_validation_error_nn = mean_nn/folds;\n",
    "\n",
    "print(\"Mean NB validation error: \", mean_validation_error_nb)\n",
    "print(\"Mean LR validation error: \",mean_validation_error_lr)\n",
    "print(\"Mean NN validation error: \",mean_validation_error_nn)\n",
    "\n",
    "nb_sum = 0\n",
    "lr_sum = 0\n",
    "nn_sum = 0\n",
    "\n",
    "# now calculation the standard deviation\n",
    "for i in range(folds):\n",
    "\n",
    "    nb_sum = nb_sum + math.pow((validation_errors_nb[i] - mean_validation_error_nb), 2)\n",
    "    lr_sum = lr_sum + math.pow((validation_errors_lr[i] - mean_validation_error_lr), 2)\n",
    "    nn_sum = nn_sum + math.pow((validation_errors_nn[i] - mean_validation_error_nn), 2)\n",
    "\n",
    "standard_deviation_nb = math.sqrt(nb_sum/folds)\n",
    "standard_deviation_lr = math.sqrt(lr_sum/folds)\n",
    "standard_deviation_nn = math.sqrt(nn_sum/folds)\n",
    "\n",
    "print(\"\\nStandard deviation for NB classifier: \", standard_deviation_nb)\n",
    "print(\"Standard deviation for LR classifier: \", standard_deviation_lr)\n",
    "print(\"Standard deviation for NN classifier: \", standard_deviation_nn)\n",
    "\n",
    "    \n",
    "# calculating standard error , substituting p= 0.2 here\n",
    "std_error_nb = (math.sqrt(folds))*(mean_validation_error_nb - 0.2)/standard_deviation_nb\n",
    "std_error_lr = (math.sqrt(folds))*(mean_validation_error_lr - 0.2)/standard_deviation_lr\n",
    "std_error_nn = (math.sqrt(folds))*(mean_validation_error_nn - 0.2)/standard_deviation_nn\n",
    "\n",
    "print(\"\\nStandard error for NB classifier: \", std_error_nb)\n",
    "print(\"Standard error for LR classifier: \", std_error_lr)\n",
    "print(\"Standard error for NN classifier: \", std_error_nn)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.is the error of naive bayes <0.2 with confidence 0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.have  naive bayes and knn the same error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean diffrence of KNN and NB classifier errors :  0.05987696514012305\n"
     ]
    }
   ],
   "source": [
    "# for knn and NB\n",
    "diff = 0\n",
    "for i in range(folds):\n",
    "    diff = diff + abs(validation_errors_nn[i]-validation_errors_nb[i])\n",
    "mean_diff = diff/folds;\n",
    "print(\"mean diffrence of KNN and NB classifier errors : \",mean_diff)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "From above calculations and using null hypothesis, we can say that the KNN and NB classifier are quite\n",
    "similar. However, they are not exactly same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.do the three classifiers have different errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
