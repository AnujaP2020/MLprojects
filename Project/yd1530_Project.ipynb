{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project\n",
    "\n",
    "### Name:  Anuja Gururaj Patil (NetId: yd1530)                                                              \n",
    "### Name:  Fnu,Sharmila Bolikoppa Palakshappa (Net Id : bm6575)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 [3pts]: Use MLP (neural network) with 5 different sets of parameters (changing for example, #hidden layers, #units  in each layer, regularization, learning rate). Report the training and test errors and the parameters you used for each setting in a table as shown above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn import cluster\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# loading and storing train test data\n",
    "df_train = read_csv('/media/anuja/study/Anuja/MS/CS_697A_ML/project/diabetes_train.csv')\n",
    "df_test = read_csv('/media/anuja/study/Anuja/MS/CS_697A_ML/project/diabetes_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train_error</th>\n",
       "      <th>Test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 500}</td>\n",
       "      <td>0.315871</td>\n",
       "      <td>0.394958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 1000}</td>\n",
       "      <td>0.280431</td>\n",
       "      <td>0.369748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'adaptive', 'max_iter': 500}</td>\n",
       "      <td>0.265023</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'adaptive', 'max_iter': 1000}</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'invscaling', 'max_iter': 500}</td>\n",
       "      <td>0.147920</td>\n",
       "      <td>0.310924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'invscaling', 'max_iter': 1000}</td>\n",
       "      <td>0.149461</td>\n",
       "      <td>0.361345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 500}</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.327731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 1000}</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>0.277311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 Parameters  \\\n",
       "0  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 500}     \n",
       "1  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 1000}    \n",
       "2  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'adaptive', 'max_iter': 500}       \n",
       "3  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'adaptive', 'max_iter': 1000}      \n",
       "4  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'invscaling', 'max_iter': 500}    \n",
       "5  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'invscaling', 'max_iter': 1000}   \n",
       "6  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 500}      \n",
       "7  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 1000}     \n",
       "\n",
       "   Train_error  Test_error  \n",
       "0  0.315871     0.394958    \n",
       "1  0.280431     0.369748    \n",
       "2  0.265023     0.352941    \n",
       "3  0.322034     0.378151    \n",
       "4  0.147920     0.310924    \n",
       "5  0.149461     0.361345    \n",
       "6  0.118644     0.327731    \n",
       "7  0.112481     0.277311    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test error using MLP Classifier is :  0.2773109243697479\n",
      "\n",
      "The best error for the parameters:  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "# MLP classifier\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# storing parameters as key value pair\n",
    "def get_params():\n",
    "    parameters = ({'hidden_layer_sizes':[(10,50),(70,100)], 'max_iter':[500, 1000] , \n",
    "                  'learning_rate': ['invscaling','adaptive'], 'alpha':[0.001] , 'activation':['tanh']})\n",
    "    items = sorted(parameters.items())\n",
    "    keys, values = zip(*items)\n",
    "    for v in product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        yield params\n",
    "        \n",
    "# creating model, fitting it and finding tain and test error\n",
    "def mlp_model(params,df_train,df_test):\n",
    "    mlp = MLPClassifier(**params)\n",
    "    mlp.fit(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    train_error = 1 - mlp.score(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    test_error = 1 - mlp.score(df_test.drop(columns=['Outcome']), df_test['Outcome'])\n",
    "    return train_error,test_error\n",
    "\n",
    "params = get_params()\n",
    "results = []\n",
    "# loop to pass each set of parameter at a time\n",
    "for p in params:\n",
    "    mlp_train_error,mlp_test_error = mlp_model(p,df_train,df_test)\n",
    "    results.append([p,mlp_train_error,mlp_test_error])\n",
    "\n",
    "# creating data frame and storing the results into it\n",
    "columns = [\"Parameters\",\"Train_error\",\"Test_error\"]\n",
    "df_results = pd.DataFrame(results,columns=columns)   \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(df_results)\n",
    "\n",
    "# to get the index of the min test error value and its parameters\n",
    "index = df_results[['Test_error']].idxmin().values[0]\n",
    "\n",
    "# printing the best test error and set of parameters for the same\n",
    "print(\"The best test error using MLP Classifier is : \" ,df_results.Test_error[index])\n",
    "print(\"\\nThe best error for the parameters: \",df_results.Parameters[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 [3pts]: Use decision tree with 5 different sets of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train_error</th>\n",
       "      <th>Test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.269646</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 10}</td>\n",
       "      <td>0.228043</td>\n",
       "      <td>0.226891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 10}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.217257</td>\n",
       "      <td>0.226891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.214176</td>\n",
       "      <td>0.277311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              Parameters  \\\n",
       "0    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}      \n",
       "1    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 1.0}      \n",
       "2    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 10}       \n",
       "3    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 0.1}      \n",
       "4    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}      \n",
       "..                                                                                                                ...      \n",
       "103  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}   \n",
       "104  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 10}    \n",
       "105  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}     \n",
       "106  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 1.0}     \n",
       "107  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}      \n",
       "\n",
       "     Train_error  Test_error  \n",
       "0    0.269646     0.235294    \n",
       "1    0.343606     0.378151    \n",
       "2    0.228043     0.226891    \n",
       "3    0.343606     0.378151    \n",
       "4    0.343606     0.378151    \n",
       "..        ...          ...    \n",
       "103  0.343606     0.378151    \n",
       "104  0.343606     0.378151    \n",
       "105  0.217257     0.226891    \n",
       "106  0.343606     0.378151    \n",
       "107  0.214176     0.277311    \n",
       "\n",
       "[108 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test error using DecisionTree Classifier is :  0.2100840336134454\n",
      "\n",
      "The best error for the parameters:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}\n"
     ]
    }
   ],
   "source": [
    "## decision tree classifier\n",
    "\n",
    "def get_params():\n",
    "    parameters = ({'max_features': ['auto', 'sqrt', 'log2'], \n",
    "                  'min_samples_leaf':[0.1, 0.5, 5],\n",
    "                     'min_samples_split':[0.1, 1.0, 10],\n",
    "                      'criterion':['gini','entropy'],\n",
    "                        'max_depth':[2, 5],})\n",
    "    items = sorted(parameters.items())\n",
    "    keys, values = zip(*items)\n",
    "    for v in product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        yield params\n",
    "        \n",
    "def dt_model(params,df_train,df_test):\n",
    "    dt = DecisionTreeClassifier(**params)\n",
    "    dt.fit(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    train_error = 1 - dt.score(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    test_error = 1 - dt.score(df_test.drop(columns=['Outcome']), df_test['Outcome'])\n",
    "    return train_error,test_error\n",
    "\n",
    "params = get_params()\n",
    "results = []\n",
    "for p in params:\n",
    "    dt_train_error,dt_test_error = dt_model(p,df_train,df_test)\n",
    "    results.append([p,dt_train_error,dt_test_error])\n",
    "\n",
    "columns = [\"Parameters\",\"Train_error\",\"Test_error\"]\n",
    "df_results2 = pd.DataFrame(results,columns=columns)   \n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(Result)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(df_results2)\n",
    "\n",
    "# to get the index of the min test error value and its parameters\n",
    "index = df_results2[['Test_error']].idxmin().values[0]\n",
    "\n",
    "print(\"The best test error using DecisionTree Classifier is : \" , df_results2.Test_error[index] )\n",
    "print(\"\\nThe best error for the parameters: \",df_results2.Parameters[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q3 [3pts]: Use random forest with 5 different sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train_error</th>\n",
       "      <th>Test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.257319</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 10}</td>\n",
       "      <td>0.285054</td>\n",
       "      <td>0.310924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 10}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.197227</td>\n",
       "      <td>0.226891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.164869</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              Parameters  \\\n",
       "0    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}      \n",
       "1    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 1.0}      \n",
       "2    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 10}       \n",
       "3    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 0.1}      \n",
       "4    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}      \n",
       "..                                                                                                                ...      \n",
       "103  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}   \n",
       "104  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 10}    \n",
       "105  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}     \n",
       "106  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 1.0}     \n",
       "107  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}      \n",
       "\n",
       "     Train_error  Test_error  \n",
       "0    0.257319     0.285714    \n",
       "1    0.343606     0.378151    \n",
       "2    0.285054     0.310924    \n",
       "3    0.343606     0.378151    \n",
       "4    0.343606     0.378151    \n",
       "..        ...          ...    \n",
       "103  0.343606     0.378151    \n",
       "104  0.343606     0.378151    \n",
       "105  0.197227     0.226891    \n",
       "106  0.343606     0.378151    \n",
       "107  0.164869     0.235294    \n",
       "\n",
       "[108 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test error using Random Forest Classifier is :  0.2100840336134454\n",
      "\n",
      "The best error for the parameters:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "## random forest classifier\n",
    "\n",
    "def get_params():\n",
    "    parameters = ({'max_features': ['auto', 'sqrt', 'log2'], \n",
    "                  'min_samples_leaf':[0.1, 0.5, 5],\n",
    "                     'min_samples_split':[0.1, 1.0, 10],\n",
    "                      'criterion':['gini','entropy'],\n",
    "                        'max_depth':[2, 5],})\n",
    "    items = sorted(parameters.items())\n",
    "    keys, values = zip(*items)\n",
    "    for v in product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        yield params\n",
    "        \n",
    "def rf_model(params,df_train,df_test):\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf.fit(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    train_error = 1 - rf.score(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    test_error = 1 - rf.score(df_test.drop(columns=['Outcome']), df_test['Outcome'])\n",
    "    return train_error,test_error\n",
    "\n",
    "params = get_params()\n",
    "results = []\n",
    "for p in params:\n",
    "    rf_train_error,rf_test_error = rf_model(p,df_train,df_test)\n",
    "    results.append([p,rf_train_error,rf_test_error])\n",
    "\n",
    "columns = [\"Parameters\",\"Train_error\",\"Test_error\"]\n",
    "df_results3 = pd.DataFrame(results,columns=columns)   \n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(Result)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(df_results3)\n",
    "\n",
    "# to get the index of the min test error value and its parameters\n",
    "index = df_results3[['Test_error']].idxmin().values[0]\n",
    "\n",
    "print(\"The best test error using Random Forest Classifier is : \", df_results3.Test_error[index]) \n",
    "print(\"\\nThe best error for the parameters: \",df_results3.Parameters[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Use gradient boosting classifier with 5 different sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "      <td>152</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.730</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>440</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.134</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>144</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.447</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "      <td>159</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.455</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>11</td>\n",
       "      <td>136</td>\n",
       "      <td>84</td>\n",
       "      <td>35</td>\n",
       "      <td>130</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.260</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0    6            148      72             35             0        33.6   \n",
       "1    1            85       66             29             0        26.6   \n",
       "2    8            183      64             0              0        23.3   \n",
       "3    1            89       66             23             94       28.1   \n",
       "4    0            137      40             35             168      43.1   \n",
       "..  ..            ...      ..             ..             ...       ...   \n",
       "644  3            103      72             30             152      27.6   \n",
       "645  2            157      74             35             440      39.4   \n",
       "646  1            167      74             17             144      23.4   \n",
       "647  0            179      50             36             159      37.8   \n",
       "648  11           136      84             35             130      28.3   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0    0.627                     50   1        \n",
       "1    0.351                     31   0        \n",
       "2    0.672                     32   1        \n",
       "3    0.167                     21   0        \n",
       "4    2.288                     33   1        \n",
       "..     ...                     ..  ..        \n",
       "644  0.730                     27   0        \n",
       "645  0.134                     30   0        \n",
       "646  0.447                     33   1        \n",
       "647  0.455                     22   1        \n",
       "648  0.260                     42   1        \n",
       "\n",
       "[649 rows x 9 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = (pd.read_csv('/media/anuja/study/Anuja/MS/CS_697A_ML/project/diabetes_train.csv',\n",
    "                         sep=\",\"))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.133</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.234</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>106</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.466</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>74</td>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.269</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.455</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0    0            107      60             25             0        26.4   \n",
       "1    1            91       54             25             100      25.2   \n",
       "2    1            117      60             23             106      33.8   \n",
       "3    5            123      74             40             77       34.1   \n",
       "4    2            120      54             0              0        26.8   \n",
       "..  ..            ...      ..            ..             ..         ...   \n",
       "114  10           101      76             48             180      32.9   \n",
       "115  2            122      70             27             0        36.8   \n",
       "116  5            121      72             23             112      26.2   \n",
       "117  1            126      60             0              0        30.1   \n",
       "118  1            93       70             31             0        30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0    0.133                     23   0        \n",
       "1    0.234                     23   0        \n",
       "2    0.466                     27   0        \n",
       "3    0.269                     28   0        \n",
       "4    0.455                     27   0        \n",
       "..     ...                     ..  ..        \n",
       "114  0.171                     63   0        \n",
       "115  0.340                     27   0        \n",
       "116  0.245                     30   0        \n",
       "117  0.349                     47   1        \n",
       "118  0.315                     23   0        \n",
       "\n",
       "[119 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = (pd.read_csv('/media/anuja/study/Anuja/MS/CS_697A_ML/project/diabetes_test.csv',\n",
    "                         sep=\",\"))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 8)\n",
      "(649,)\n",
      "(119, 8)\n",
      "(119,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the train and test data into training and testing values\n",
    "\n",
    "X_train = train_data.drop(columns = 'Outcome', axis =1)\n",
    "Y_train = train_data.Outcome\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "X_test = test_data.drop(columns = 'Outcome', axis =1)\n",
    "Y_test = test_data.Outcome\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train_error</th>\n",
       "      <th>Test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.243697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'validation_fraction': 0.3}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}</td>\n",
       "      <td>0.117103</td>\n",
       "      <td>0.226891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5, 'validation_fraction': 0.3}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'criterion': 'mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'validation_fraction': 0.3}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'criterion': 'mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}</td>\n",
       "      <td>0.117103</td>\n",
       "      <td>0.226891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'criterion': 'mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5, 'validation_fraction': 0.3}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Parameters  \\\n",
       "0  {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}   \n",
       "1  {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'validation_fraction': 0.3}   \n",
       "2  {'criterion': 'friedman_mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}   \n",
       "3  {'criterion': 'friedman_mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5, 'validation_fraction': 0.3}   \n",
       "4  {'criterion': 'mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}            \n",
       "5  {'criterion': 'mse', 'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'validation_fraction': 0.3}            \n",
       "6  {'criterion': 'mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}            \n",
       "7  {'criterion': 'mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5, 'validation_fraction': 0.3}            \n",
       "\n",
       "   Train_error  Test_error  \n",
       "0  0.152542     0.243697    \n",
       "1  0.000000     0.235294    \n",
       "2  0.117103     0.226891    \n",
       "3  0.000000     0.252101    \n",
       "4  0.152542     0.235294    \n",
       "5  0.000000     0.226891    \n",
       "6  0.117103     0.226891    \n",
       "7  0.000000     0.235294    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test error using GradientBoostingClassifier is :  0.22689075630252098\n",
      "\n",
      "The best error for the parameters:  {'criterion': 'friedman_mse', 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 2, 'validation_fraction': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# GradientBoosting Classifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from itertools import product\n",
    "\n",
    "# creating parameters set\n",
    "def get_params():\n",
    "    parameters = ({'loss': ['exponential'], \n",
    "                  'learning_rate':[0.1, 0.2],\n",
    "                     'validation_fraction':[0.3],\n",
    "                      'criterion':['friedman_mse','mse'],\n",
    "                        'max_depth':[2, 5],})\n",
    "    items = sorted(parameters.items())\n",
    "    keys, values = zip(*items)\n",
    "    for v in product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        yield params\n",
    "        \n",
    "def gbc_model(params):\n",
    "    gbc = GradientBoostingClassifier(**params)\n",
    "    gbc.fit(X_train, Y_train)\n",
    "    train_error = 1 - gbc.score(X_train, Y_train)\n",
    "    test_error = 1 - gbc.score(X_test, Y_test)\n",
    "    return train_error,test_error\n",
    "\n",
    "params = get_params()\n",
    "results = []\n",
    "for p in params:\n",
    "    gbc_train_error,gbc_test_error = gbc_model(p)\n",
    "    results.append([p,gbc_train_error,gbc_test_error])\n",
    "\n",
    "columns = [\"Parameters\",\"Train_error\",\"Test_error\"]\n",
    "Result = pd.DataFrame(results,columns=columns)   \n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be \n",
    "# specified also\n",
    "#     display(Result)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(Result)\n",
    "\n",
    "# to get the index of the min test error value and its parameters\n",
    "index = Result[['Test_error']].idxmin().values[0]\n",
    "\n",
    "print(\"The best test error using GradientBoostingClassifier is : \" , Result.Test_error[index])\n",
    "print(\"\\nThe best error for the parameters: \",Result.Parameters[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Combine the classifiers with the best test error you produced in Q1..Q4 using VotingClassifier and measure the training and test error for each of the following cases:  \n",
    "a) give equal weight to each classifier \n",
    "b) give weight proportional to 1/(1+trainingerror) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.29 [MLP]\n",
      "Train error: 0.30 [Decision Tree]\n",
      "Train error: 0.17 [Random Forest]\n",
      "Train error: 0.00 [Gradient Boost]\n",
      "Train error: 0.05 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# combining the classifiers with the best test errors from above questions 1 to 4 using VotingClassifier\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# passing set of parameters from above classifiers having best test error\n",
    "\n",
    "clf1 = MLPClassifier(activation= 'tanh', alpha = 0.001, hidden_layer_sizes = (10, 50),\n",
    "                     learning_rate = 'adaptive', max_iter = 500)\n",
    "clf2 = DecisionTreeClassifier(criterion = 'gini', max_depth = 2, max_features = 'sqrt',\n",
    "                              min_samples_leaf = 5, min_samples_split = 10)\n",
    "clf3 = RandomForestClassifier(criterion = 'entropy', max_depth = 5, max_features = 'auto',\n",
    "                              min_samples_leaf =  5, min_samples_split = 10)\n",
    "clf4 = GradientBoostingClassifier(criterion = 'friedman_mse', learning_rate = 0.1, \n",
    "                                  loss =  'exponential', max_depth =  5, validation_fraction = 0.3)\n",
    "\n",
    "# for part a) creating model here and passing equal weights to each classifier\n",
    "eclf = VotingClassifier(\n",
    "              estimators=[('mlp', clf1), ('dt', clf2), ('rf', clf3), ('gb', clf4)],\n",
    "              voting='soft', weights=[1, 1, 1, 1])\n",
    "\n",
    "# calculating training error\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['MLP', 'Decision Tree','Random Forest', \n",
    "                                                       'Gradient Boost','Ensemble']):    \n",
    "    clf.fit(X_train,Y_train)\n",
    "    print(\"Train error: %0.2f [%s]\" % (1-clf.score(X_train, Y_train), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.37 [MLP]\n",
      "Test error: 0.35 [Decision Tree]\n",
      "Test error: 0.24 [Random Forest]\n",
      "Test error: 0.23 [Gradient Boost]\n",
      "Test error: 0.19 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# calculating testing error\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['MLP', 'Decision Tree','Random Forest', \n",
    "                                                       'Gradient Boost','Ensemble']):    \n",
    "    print(\"Test error: %0.2f [%s]\" % (1-clf.score(X_test, Y_test), label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.25 [MLP]\n",
      "Train error: 0.27 [Decision Tree]\n",
      "Train error: 0.17 [Random Forest]\n",
      "Train error: 0.00 [Gradient Boost]\n",
      "Train error: 0.08 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# for part b), giving weight proportional to 1/(1+trainingerror)\n",
    "\n",
    "# asisgning best training error from each classifier used in above questions\n",
    "eclf = VotingClassifier(\n",
    "              estimators=[('mlp', clf1), ('dt', clf2), ('rf', clf3), ('gb', clf4)],\n",
    "              voting='soft', weights=[1/(1+min(df_results.Train_error)),\n",
    "                                                    1/(1+min(df_results2.Train_error)),\n",
    "                                                    1/(1+min(df_results3.Train_error)),\n",
    "                                                    1/(1+min(Result.Train_error))])\n",
    "                                      \n",
    "# calculating training error\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['MLP', 'Decision Tree','Random Forest', \n",
    "                                                       'Gradient Boost','Ensemble']):    \n",
    "    clf.fit(X_train,Y_train)\n",
    "    print(\"Train error: %0.2f [%s]\" % (1-clf.score(X_train, Y_train), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.34 [MLP]\n",
      "Test error: 0.24 [Decision Tree]\n",
      "Test error: 0.24 [Random Forest]\n",
      "Test error: 0.21 [Gradient Boost]\n",
      "Test error: 0.24 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# calculating testing error\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['MLP', 'Decision Tree','Random Forest', \n",
    "                                                       'Gradient Boost','Ensemble']):    \n",
    "    print(\"Test error: %0.2f [%s]\" % (1-clf.score(X_test, Y_test), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
