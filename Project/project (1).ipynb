{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project\n",
    "\n",
    "### Name:  Anuja (NetId:)                                                              \n",
    "### Name:  Fnu,Sharmila Bolikoppa Palakshappa (Net Id : bm6575)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 [3pts]: Use MLP (neural network) with 5 different sets of parameters (changing for example, #hidden layers, #units  in each layer, regularization, learning rate). Report the training and test errors and the parameters you used for each setting in a table as shown above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn import cluster\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "df_train = read_csv('diabetes_train.csv')\n",
    "df_test = read_csv('diabetes_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train_error</th>\n",
       "      <th>Test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 500}</td>\n",
       "      <td>0.308166</td>\n",
       "      <td>0.369748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 1000}</td>\n",
       "      <td>0.314330</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'adaptive', 'max_iter': 500}</td>\n",
       "      <td>0.278891</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'adaptive', 'max_iter': 1000}</td>\n",
       "      <td>0.246533</td>\n",
       "      <td>0.302521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'invscaling', 'max_iter': 500}</td>\n",
       "      <td>0.171032</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'invscaling', 'max_iter': 1000}</td>\n",
       "      <td>0.121726</td>\n",
       "      <td>0.394958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 500}</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.386555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 1000}</td>\n",
       "      <td>0.147920</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 Parameters  \\\n",
       "0  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 500}     \n",
       "1  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 1000}    \n",
       "2  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'adaptive', 'max_iter': 500}       \n",
       "3  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'adaptive', 'max_iter': 1000}      \n",
       "4  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'invscaling', 'max_iter': 500}    \n",
       "5  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'invscaling', 'max_iter': 1000}   \n",
       "6  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 500}      \n",
       "7  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (70, 100), 'learning_rate': 'adaptive', 'max_iter': 1000}     \n",
       "\n",
       "   Train_error  Test_error  \n",
       "0  0.308166     0.369748    \n",
       "1  0.314330     0.378151    \n",
       "2  0.278891     0.378151    \n",
       "3  0.246533     0.302521    \n",
       "4  0.171032     0.378151    \n",
       "5  0.121726     0.394958    \n",
       "6  0.186441     0.386555    \n",
       "7  0.147920     0.378151    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test error using MLP Classifier is : 0.3025210084033614\n",
      "\n",
      "The best error for the parameters:  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10, 50), 'learning_rate': 'invscaling', 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def get_params():\n",
    "    parameters = {'hidden_layer_sizes':[(10,50),(70,100)], 'max_iter':[500, 1000] , 'learning_rate': ['invscaling','adaptive'], 'alpha':[0.001] , 'activation':['tanh']}\n",
    "    items = sorted(parameters.items())\n",
    "    keys, values = zip(*items)\n",
    "    for v in product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        yield params\n",
    "\n",
    "def mlp_model(params,df_train,df_test):\n",
    "    mlp = MLPClassifier(**params)\n",
    "    mlp.fit(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    train_error = 1 - mlp.score(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    test_error = 1 - mlp.score(df_test.drop(columns=['Outcome']), df_test['Outcome'])\n",
    "    return train_error,test_error\n",
    "\n",
    "params = get_params()\n",
    "results = []\n",
    "for p in params:\n",
    "    mlp_train_error,mlp_test_error = mlp_model(p,df_train,df_test)\n",
    "    results.append([p,mlp_train_error,mlp_test_error])\n",
    "\n",
    "columns = [\"Parameters\",\"Train_error\",\"Test_error\"]\n",
    "df_results = pd.DataFrame(results,columns=columns)   \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(df_results)\n",
    "\n",
    "print(\"The best test error using MLP Classifier is : \" + str(min(df_results.Test_error)) )\n",
    "print(\"\\nThe best error for the parameters: \",df_results.Parameters[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 [3pts]: Use decision tree with 5 different sets of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train_error</th>\n",
       "      <th>Test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.228043</td>\n",
       "      <td>0.226891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 10}</td>\n",
       "      <td>0.323575</td>\n",
       "      <td>0.369748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 10}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.211094</td>\n",
       "      <td>0.260504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.315871</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.228043</td>\n",
       "      <td>0.336134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              Parameters  \\\n",
       "0    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}      \n",
       "1    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 1.0}      \n",
       "2    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 10}       \n",
       "3    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 0.1}      \n",
       "4    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}      \n",
       "..                                                                                                                ...      \n",
       "103  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}   \n",
       "104  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 10}    \n",
       "105  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}     \n",
       "106  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 1.0}     \n",
       "107  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}      \n",
       "\n",
       "     Train_error  Test_error  \n",
       "0    0.228043     0.226891    \n",
       "1    0.343606     0.378151    \n",
       "2    0.323575     0.369748    \n",
       "3    0.343606     0.378151    \n",
       "4    0.343606     0.378151    \n",
       "..        ...          ...    \n",
       "103  0.343606     0.378151    \n",
       "104  0.343606     0.378151    \n",
       "105  0.211094     0.260504    \n",
       "106  0.315871     0.352941    \n",
       "107  0.228043     0.336134    \n",
       "\n",
       "[108 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test error using DecisionTree Classifier is : 0.2016806722689075\n",
      "\n",
      "The best error for the parameters:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "## decision tree classifier\n",
    "def get_params():\n",
    "    parameters = ({'max_features': ['auto', 'sqrt', 'log2'], \n",
    "                  'min_samples_leaf':[0.1, 0.5, 5],\n",
    "                     'min_samples_split':[0.1, 1.0, 10],\n",
    "                      'criterion':['gini','entropy'],\n",
    "                        'max_depth':[2, 5],})\n",
    "    items = sorted(parameters.items())\n",
    "    keys, values = zip(*items)\n",
    "    for v in product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        yield params\n",
    "        \n",
    "def dt_model(params,df_train,df_test):\n",
    "    dt = DecisionTreeClassifier(**params)\n",
    "    dt.fit(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    train_error = 1 - dt.score(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    test_error = 1 - dt.score(df_test.drop(columns=['Outcome']), df_test['Outcome'])\n",
    "    return train_error,test_error\n",
    "\n",
    "params = get_params()\n",
    "results = []\n",
    "for p in params:\n",
    "    dt_train_error,dt_test_error = dt_model(p,df_train,df_test)\n",
    "    results.append([p,dt_train_error,dt_test_error])\n",
    "\n",
    "columns = [\"Parameters\",\"Train_error\",\"Test_error\"]\n",
    "df_results = pd.DataFrame(results,columns=columns)   \n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(Result)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(df_results)\n",
    "\n",
    "print(\"The best test error using DecisionTree Classifier is : \" + str(min(df_results.Test_error)) )\n",
    "print(\"\\nThe best error for the parameters: \",df_results.Parameters[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q3 [3pts]: Use random forest with 5 different sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train_error</th>\n",
       "      <th>Test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.240370</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 10}</td>\n",
       "      <td>0.265023</td>\n",
       "      <td>0.277311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 10}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}</td>\n",
       "      <td>0.191063</td>\n",
       "      <td>0.243697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 1.0}</td>\n",
       "      <td>0.343606</td>\n",
       "      <td>0.378151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.164869</td>\n",
       "      <td>0.226891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              Parameters  \\\n",
       "0    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 0.1}      \n",
       "1    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 1.0}      \n",
       "2    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.1, 'min_samples_split': 10}       \n",
       "3    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 0.1}      \n",
       "4    {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}      \n",
       "..                                                                                                                ...      \n",
       "103  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 1.0}   \n",
       "104  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.5, 'min_samples_split': 10}    \n",
       "105  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 0.1}     \n",
       "106  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 1.0}     \n",
       "107  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}      \n",
       "\n",
       "     Train_error  Test_error  \n",
       "0    0.240370     0.252101    \n",
       "1    0.343606     0.378151    \n",
       "2    0.265023     0.277311    \n",
       "3    0.343606     0.378151    \n",
       "4    0.343606     0.378151    \n",
       "..        ...          ...    \n",
       "103  0.343606     0.378151    \n",
       "104  0.343606     0.378151    \n",
       "105  0.191063     0.243697    \n",
       "106  0.343606     0.378151    \n",
       "107  0.164869     0.226891    \n",
       "\n",
       "[108 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test error using Random Forest Classifier is : 0.19327731092436973\n",
      "\n",
      "The best error for the parameters:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 0.5, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "## random forest classifier\n",
    "def get_params():\n",
    "    parameters = ({'max_features': ['auto', 'sqrt', 'log2'], \n",
    "                  'min_samples_leaf':[0.1, 0.5, 5],\n",
    "                     'min_samples_split':[0.1, 1.0, 10],\n",
    "                      'criterion':['gini','entropy'],\n",
    "                        'max_depth':[2, 5],})\n",
    "    items = sorted(parameters.items())\n",
    "    keys, values = zip(*items)\n",
    "    for v in product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        yield params\n",
    "        \n",
    "def rf_model(params,df_train,df_test):\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf.fit(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    train_error = 1 - rf.score(df_train.drop(columns=['Outcome']), df_train['Outcome'])\n",
    "    test_error = 1 - rf.score(df_test.drop(columns=['Outcome']), df_test['Outcome'])\n",
    "    return train_error,test_error\n",
    "\n",
    "params = get_params()\n",
    "results = []\n",
    "for p in params:\n",
    "    rf_train_error,rf_test_error = rf_model(p,df_train,df_test)\n",
    "    results.append([p,rf_train_error,rf_test_error])\n",
    "\n",
    "columns = [\"Parameters\",\"Train_error\",\"Test_error\"]\n",
    "df_results = pd.DataFrame(results,columns=columns)   \n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(Result)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(df_results)\n",
    "\n",
    "print(\"The best test error using Random Forest Classifier is : \" + str(min(df_results.Test_error)) )\n",
    "print(\"\\nThe best error for the parameters: \",df_results.Parameters[5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
