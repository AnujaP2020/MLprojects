{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025c1061",
   "metadata": {},
   "source": [
    "1.Import relevant commands for numpy, pandas, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eab4009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d5f11",
   "metadata": {},
   "source": [
    "Q1: Create the following training datasets from the optdigits.tra set: \n",
    "X25: Randomly chosen N=25 instances from each class. \n",
    "X100:  Randomly chosen N=100 instances from each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "217d21c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Read Training Data\n",
    "train_data = read_csv(r'C:\\Users\\gangareddy\\Documents\\GitHub\\MLprojects\\Assignment3\\optdigits.tra', sep=\",\",header=None)\n",
    "test_data= read_csv(r'C:\\Users\\gangareddy\\Documents\\GitHub\\MLprojects\\Assignment3\\optdigits.tes', sep=\",\",header=None)\n",
    "#print(train_data.head())\n",
    "train_data\n",
    "test_data\n",
    "\n",
    "Xtrain_25 = train_data[train_data[64] == 0].sample(25)\n",
    "Xtrain_100 = train_data[train_data[64] == 0].sample(100)\n",
    "#print(Xtrain_25)\n",
    "#print(Xtrain_100)\n",
    "\n",
    "\n",
    "classes = 10\n",
    "X25_train = train_data[train_data[64] == 0].sample(25)\n",
    "X100_train = train_data[train_data[64] == 0].sample(100)\n",
    "#print(X25_train)\n",
    "# print(X100_train)\n",
    "for i in range(1,classes,1):\n",
    "\n",
    "    X25_train = X25_train.append(train_data[train_data[64] == i].sample(25), ignore_index = True)\n",
    "    X100_train = X100_train.append(train_data[train_data[64] == i].sample(100), ignore_index= True)\n",
    "\n",
    "    \n",
    "# get the X_train and Y_train\n",
    "\n",
    "X_train_25 = X25_train.iloc[:,0:64]\n",
    "Y_train_25 = X25_train.iloc[:,64];  #classification or label column\n",
    "\n",
    "X_train_100 = X100_train.iloc[:,0:64]\n",
    "Y_train_100 = X100_train.iloc[:,64];\n",
    "\n",
    "# X_test = test_data.iloc[:,0:64]\n",
    "# Y_test = test_data.iloc[:,64]\n",
    "X_test = test_data[test_data.columns[0:64]]\n",
    "Y_test = test_data[test_data.columns[64]]\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(type(X_test))\n",
    "print(type(Y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4d25d",
   "metadata": {},
   "source": [
    "Q2: Decision Trees, classification: \n",
    "Use library sklearn.tree.DecisionTreeClassifier\n",
    " algorithm. For the DecisionTreeClassifier determine the value of the tree depth parameter (experiment with depth=2, 3, 5, 10)  that results in the best test error. Report the training and test errors for each depth value and the training set. How does the best depth value change as the number of instances change? \n",
    "Note: Check the depth of the your trained decision tree, by e.g. plotting the tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a25b964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 25 instances\n",
      "                Training Error  Test Error\n",
      "Max_Depth = 2            0.620    0.643294\n",
      "Max_Depth = 3            0.448    0.562048\n",
      "Max_Depth = 5            0.172    0.373400\n",
      "Max_Depth = 10           0.012    0.326656\n",
      "\n",
      "Results with 100 instances\n",
      "                Training Error  Test Error\n",
      "Max_Depth = 2            0.695    0.702282\n",
      "Max_Depth = 3            0.591    0.636060\n",
      "Max_Depth = 5            0.247    0.331107\n",
      "Max_Depth = 10           0.012    0.203673\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TrainingError_25 = []\n",
    "TestingError_25=[]\n",
    "\n",
    "TrainingError_100 = []\n",
    "TestingError_100=[]\n",
    "index=[]\n",
    "\n",
    "#storing the max_depth parameters in a list\n",
    "mdepth=[2,3,5,10]\n",
    "#train with 25 instances from each class\n",
    "\n",
    "\n",
    "for i in mdepth:\n",
    "        model = DecisionTreeClassifier(max_depth=i)\n",
    "        model.fit(X_train_25,Y_train_25)\n",
    "        a1=model.score(X_train_25,Y_train_25)\n",
    "        a2=model.score(X_test,Y_test)\n",
    "        TrainingError_25.append(1-a1)\n",
    "        TestingError_25.append(1-a2)\n",
    "\n",
    "#train with 100 instances from each class\n",
    "\n",
    "for i in mdepth:\n",
    "        model = DecisionTreeClassifier(max_depth=i)\n",
    "        model.fit(X_train_100,Y_train_100)\n",
    "        y_pred = model.predict(X_train_100)\n",
    "        y_pred1= model.predict(X_test)\n",
    "        x1=accuracy_score(Y_train_100,y_pred)\n",
    "        x2=accuracy_score(Y_test,y_pred1)\n",
    "        TrainingError_100.append(1-x1)\n",
    "        TestingError_100.append(1-x2)\n",
    "        temp = 'Max_Depth = '+str(i)\n",
    "        index.append(temp)\n",
    "\n",
    "columns = ['Training Error','Test Error']\n",
    "\n",
    "Error_list_25=[]\n",
    "Error_list_100=[]\n",
    "for i in range(len(TrainingError_25)):\n",
    "    Error_list_25.append([TrainingError_25[i],TestingError_25[i]])\n",
    "    Error_list_100.append([TrainingError_100[i],TestingError_100[i]] )\n",
    "    \n",
    "print(\"Results with 25 instances\")   \n",
    "df_train_error_25 = pd.DataFrame(Error_list_25,columns=columns,index=index)\n",
    "print(df_train_error_25.head(20)) \n",
    "\n",
    "print()\n",
    "print(\"Results with 100 instances\")   \n",
    "df_train_error_100 = pd.DataFrame(Error_list_100,columns=columns,index=index)\n",
    "print(df_train_error_100.head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d2737364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfeature_names = X_train_25.columns\\n\\ndotfile = export_graphviz(model,feature_names=feature_names)\\ngraph = graphviz.Source(dotfile)\\ngraph.render(filename='tree',format='jpg',cleanup=True)\\n\\n\""
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(mdepth,TestingError_25,label='Testing error for 25 instances')\n",
    "plt.plot(mdepth,TestingError_100,label='Testing error for 100 instances')\n",
    "plt.legend()\n",
    "plt.xlabel(' Max Depth')\n",
    "plt.ylabel(' Error Rate')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "feature_names = X_train_25.columns\n",
    "\n",
    "dotfile = export_graphviz(model,feature_names=feature_names)\n",
    "graph = graphviz.Source(dotfile)\n",
    "graph.render(filename='tree',format='jpg',cleanup=True)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af32ac",
   "metadata": {},
   "source": [
    "Q2:Repeat Q1 using XGBoost and LightGBM algorithms. Experiment with at least 5 different parameter settings to see their effect on training and test errors. How do best parameters change as the #training instances change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "08b50683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ XGBOOST ALGORITHM *************\n",
      "[19:53:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 25 random instances using SET1parameters  0.0\n",
      "The testing error of 25 random instances using SET1 parameters  0.1112966054535337\n",
      "[19:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 25 random instances using SET2parameters  0.0\n",
      "The testing error of 25 random instances using SET2 parameters  0.12465219810795769\n",
      "[19:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 25 random instances using SET3parameters  0.0\n",
      "The testing error of 25 random instances using SET3 parameters  0.12966054535336669\n",
      "[19:53:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 25 random instances using SET4parameters  0.0\n",
      "The testing error of 25 random instances using SET4 parameters  0.13578185865331105\n",
      "[19:53:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 25 random instances using SET5parameters  0.016000000000000014\n",
      "The testing error of 25 random instances using SET5 parameters  0.16082359488035614\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 100 random instances using SET1parameters  0.0\n",
      "The testing error of 100 random instances using SET1 parameters  0.0673344462993879\n",
      "[19:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 100 random instances using SET2parameters  0.0\n",
      "The testing error of 100 random instances using SET2 parameters  0.0690038953811909\n",
      "[19:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 100 random instances using SET3parameters  0.0\n",
      "The testing error of 100 random instances using SET3 parameters  0.07679465776293826\n",
      "[19:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangareddy\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of 100 random instances using SET4parameters  0.0010000000000000009\n",
      "The testing error of 100 random instances using SET4 parameters  0.07512520868113526\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-496c13de69bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mxgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_child_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_child_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train_100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The training error of 100 random instances using SET\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"parameters \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train_100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#XGBOOST\n",
    "print(\"************ XGBOOST ALGORITHM *************\")\n",
    "\n",
    "print()\n",
    "print(\"For 25 random instances\")\n",
    "print()\n",
    "learning_rate= [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] \n",
    "max_depth= [3, 4, 5, 6, 8, 10, 12, 15]\n",
    "min_child_weight =[1, 3, 4, 5,7]\n",
    " #The value should be less than 1\n",
    "gamma = [0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    " #The value should be less than 1\n",
    "colsample_bytree = [0.3,0.4,0.5,0.6,0.7]\n",
    "\n",
    "for i in range(1,6,1):\n",
    "    xgb = XGBClassifier(learning_rate=learning_rate[i-1],max_depth=max_depth[i-1],min_child_weight=min_child_weight[i-1],gamma=gamma[i-1],colsample_bytree=colsample_bytree[i-1])\n",
    "    xgb.fit(X_train_25,Y_train_25)\n",
    "    print(\"The training error of 25 random instances using SET\"+str(i)+\"parameters \",1-xgb.score(X_train_25,Y_train_25))\n",
    "    print(\"The testing error of 25 random instances using SET\"+str(i)+\" parameters \",1-xgb.score(X_test,Y_test))\n",
    "    \n",
    "for i in range(1,6,1):\n",
    "    xgb = XGBClassifier(learning_rate=learning_rate[i-1],max_depth=max_depth[i-1],min_child_weight=min_child_weight[i-1],colsample_bytree=colsample_bytree[i-1])\n",
    "    xgb.fit(X_train_100,Y_train_100)\n",
    "    print(\"The training error of 100 random instances using SET\"+str(i)+\"parameters \",1-xgb.score(X_train_100,Y_train_100))\n",
    "    print(\"The testing error of 100 random instances using SET\"+str(i)+\" parameters \",1-xgb.score(X_test,Y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "424737d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ LIGHTBGM ALGORITHM *************\n",
      "\n",
      "For 25 random instances\n",
      "\n",
      "The training error of 25 random instances using SET1parameters  0.0\n",
      "The testing error of 25 random instances using SET1 parameters  0.10851419031719534\n",
      "The training error of 25 random instances using SET2parameters  0.0\n",
      "The testing error of 25 random instances using SET2 parameters  0.14134668892598778\n",
      "The training error of 25 random instances using SET3parameters  0.01200000000000001\n",
      "The testing error of 25 random instances using SET3 parameters  0.15414579855314414\n",
      "The training error of 25 random instances using SET4parameters  0.028000000000000025\n",
      "The testing error of 25 random instances using SET4 parameters  0.17417918753478023\n",
      "The training error of 25 random instances using SET5parameters  0.05600000000000005\n",
      "The testing error of 25 random instances using SET5 parameters  0.1769616026711185\n",
      "******************************\n",
      "\n",
      "For 100 random instances\n",
      "\n",
      "The training error of 100 random instances using SET1parameters  0.0\n",
      "The testing error of 100 random instances using SET1 parameters  0.0606566499721759\n",
      "The training error of 100 random instances using SET2parameters  0.0\n",
      "The testing error of 100 random instances using SET2 parameters  0.07067334446299389\n",
      "The training error of 100 random instances using SET3parameters  0.0010000000000000009\n",
      "The testing error of 100 random instances using SET3 parameters  0.07289927657206452\n",
      "The training error of 100 random instances using SET4parameters  0.0040000000000000036\n",
      "The testing error of 100 random instances using SET4 parameters  0.08736783528102388\n",
      "The training error of 100 random instances using SET5parameters  0.007000000000000006\n",
      "The testing error of 100 random instances using SET5 parameters  0.09070673344462998\n"
     ]
    }
   ],
   "source": [
    "#LIGHTBGM\n",
    "print(\"************ LIGHTBGM ALGORITHM *************\")\n",
    "print()\n",
    "print(\"For 25 random instances\")\n",
    "print()\n",
    "learning_rate= [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] \n",
    "max_depth= [3, 4, 5, 6, 8, 10, 12, 15]\n",
    "min_child_weight =[1, 3, 4, 5,7]\n",
    " #The value should be less than 1\n",
    "reg_alpha = [0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    " #The value should be less than 1\n",
    "colsample_bytree = [0.3,0.4,0.5,0.6,0.7]\n",
    "\n",
    "for i in range(1,6,1):\n",
    "    lgb = LGBMClassifier(learning_rate=learning_rate[i-1],max_depth=max_depth[i-1],min_child_weight=min_child_weight[i-1],reg_alpha=reg_alpha[i-1],colsample_bytree=colsample_bytree[i-1])\n",
    "    lgb.fit(X_train_25,Y_train_25)\n",
    "    print(\"The training error of 25 random instances using SET\"+str(i)+\"parameters \",1-lgb.score(X_train_25,Y_train_25))\n",
    "    print(\"The testing error of 25 random instances using SET\"+str(i)+\" parameters \",1-lgb.score(X_test,Y_test))\n",
    "print(\"******************************\")    \n",
    "print()\n",
    "print(\"For 100 random instances\")\n",
    "print()\n",
    "for i in range(1,6,1):\n",
    "    lgb = LGBMClassifier(learning_rate=learning_rate[i-1],max_depth=max_depth[i-1],min_child_weight=min_child_weight[i-1],reg_alpha=reg_alpha[i-1],colsample_bytree=colsample_bytree[i-1])\n",
    "    lgb.fit(X_train_100,Y_train_100)\n",
    "    print(\"The training error of 100 random instances using SET\"+str(i)+\"parameters \",1-lgb.score(X_train_100,Y_train_100))\n",
    "    print(\"The testing error of 100 random instances using SET\"+str(i)+\" parameters \",1-lgb.score(X_test,Y_test)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc1add",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
