{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323e1aa0",
   "metadata": {},
   "source": [
    "Q1: Create the following training datasets from the optdigits.tra set: \n",
    "X25: Randomly chosen N=25 instances from each class. \n",
    "X100:  Randomly chosen N=100 instances from each class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c9e1a1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.externals.six'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-e21054774776>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.externals.six'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dc16f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  55  56  57  58  59  60  61  \\\n",
       "0      0   1   6  15  12   1   0   0   0   7  ...   0   0   0   6  14   7   1   \n",
       "1      0   0  10  16   6   0   0   0   0   7  ...   0   0   0  10  16  15   3   \n",
       "2      0   0   8  15  16  13   0   0   0   1  ...   0   0   0   9  14   0   0   \n",
       "3      0   0   0   3  11  16   0   0   0   0  ...   0   0   0   0   1  15   2   \n",
       "4      0   0   5  14   4   0   0   0   0   0  ...   0   0   0   4  12  14   7   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3818   0   0   5  13  11   2   0   0   0   2  ...   0   0   0   8  13  15  10   \n",
       "3819   0   0   0   1  12   1   0   0   0   0  ...   0   0   0   0   4   9   0   \n",
       "3820   0   0   3  15   0   0   0   0   0   0  ...   0   0   0   4  14  16   9   \n",
       "3821   0   0   6  16   2   0   0   0   0   0  ...   0   0   0   5  16  16  16   \n",
       "3822   0   0   2  15  16  13   1   0   0   0  ...   0   0   0   4  14   1   0   \n",
       "\n",
       "      62  63  64  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   7  \n",
       "3      0   0   4  \n",
       "4      0   0   6  \n",
       "...   ..  ..  ..  \n",
       "3818   1   0   9  \n",
       "3819   0   0   4  \n",
       "3820   0   0   6  \n",
       "3821   5   0   6  \n",
       "3822   0   0   7  \n",
       "\n",
       "[3823 rows x 65 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting header = None here to get the column names as in order starting from 0\n",
    "\n",
    "train_data = read_csv(r'C:\\Users\\gangareddy\\Documents\\GitHub\\MLprojects\\Assignment3\\optdigits.tra', sep=\",\",header=None)\n",
    "train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bcaf38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  55  56  57  58  59  60  61  \\\n",
       "0      0   0   5  13   9   1   0   0   0   0  ...   0   0   0   6  13  10   0   \n",
       "1      0   0   0  12  13   5   0   0   0   0  ...   0   0   0   0  11  16  10   \n",
       "2      0   0   0   4  15  12   0   0   0   0  ...   0   0   0   0   3  11  16   \n",
       "3      0   0   7  15  13   1   0   0   0   8  ...   0   0   0   7  13  13   9   \n",
       "4      0   0   0   1  11   0   0   0   0   0  ...   0   0   0   0   2  16   4   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "1792   0   0   4  10  13   6   0   0   0   1  ...   0   0   0   2  14  15   9   \n",
       "1793   0   0   6  16  13  11   1   0   0   0  ...   0   0   0   6  16  14   6   \n",
       "1794   0   0   1  11  15   1   0   0   0   0  ...   0   0   0   2   9  13   6   \n",
       "1795   0   0   2  10   7   0   0   0   0   0  ...   0   0   0   5  12  16  12   \n",
       "1796   0   0  10  14   8   1   0   0   0   2  ...   0   0   1   8  12  14  12   \n",
       "\n",
       "      62  63  64  \n",
       "0      0   0   0  \n",
       "1      0   0   1  \n",
       "2      9   0   2  \n",
       "3      0   0   3  \n",
       "4      0   0   4  \n",
       "...   ..  ..  ..  \n",
       "1792   0   0   9  \n",
       "1793   0   0   0  \n",
       "1794   0   0   8  \n",
       "1795   0   0   9  \n",
       "1796   1   0   8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data= read_csv(r'C:\\Users\\gangareddy\\Documents\\GitHub\\MLprojects\\Assignment3\\optdigits.tes', sep=\",\",header=None)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79ad7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset of 25 instances of each class and 100 instances of each class\n",
    "\n",
    "classes = 10\n",
    "X25_train = train_data[train_data[64] == 0].sample(25)\n",
    "X100_train = train_data[train_data[64] == 0].sample(100)\n",
    "\n",
    "for i in range(1,classes,1):\n",
    "\n",
    "    X25_train = X25_train.append(train_data[train_data[64] == i].sample(25), ignore_index = True)\n",
    "    X100_train = X100_train.append(train_data[train_data[64] == i].sample(100), ignore_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d3b63f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# get the X_train and Y_train\n",
    "\n",
    "X_train_25 = X25_train.iloc[:,0:64]\n",
    "Y_train_25 = X25_train.iloc[:,64];  #classification or label column\n",
    "\n",
    "X_train_100 = X100_train.iloc[:,0:64]\n",
    "Y_train_100 = X100_train.iloc[:,64];\n",
    "\n",
    "X_test = test_data.iloc[:,0:64]\n",
    "Y_test = test_data.iloc[:,64]\n",
    "# X_test = test_data[test_data.columns[0:64]]\n",
    "# Y_test = test_data[test_data.columns[64]]\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(type(X_test))\n",
    "print(type(Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a80004",
   "metadata": {},
   "source": [
    "Q2: Decision Trees, classification: Use library sklearn.tree.DecisionTreeClassifier algorithm. For the DecisionTreeClassifier determine the value of the tree depth parameter (experiment with depth=2, 3, 5, 10) that results in the best test error. Report the training and test errors for each depth value and the training set. How does the best depth value change as the number of instances change? Note: Check the depth of the your trained decision tree, by e.g. plotting the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c3330d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 25 instances\n",
      "                Training Error  Test Error\n",
      "Max_Depth = 2            0.700    0.716194\n",
      "Max_Depth = 3            0.580    0.606566\n",
      "Max_Depth = 5            0.216    0.332220\n",
      "Max_Depth = 10           0.000    0.283250\n",
      "\n",
      "Results with 100 instances\n",
      "                Training Error  Test Error\n",
      "Max_Depth = 2            0.645    0.669449\n",
      "Max_Depth = 3            0.492    0.542571\n",
      "Max_Depth = 5            0.198    0.295492\n",
      "Max_Depth = 10           0.005    0.226489\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainingError_25 = []\n",
    "TestingError_25=[]\n",
    "\n",
    "TrainingError_100 = []\n",
    "TestingError_100=[]\n",
    "index=[]\n",
    "\n",
    "#storing the max_depth parameters in a list\n",
    "mdepth=[2,3,5,10]\n",
    "#train with 25 instances from each class\n",
    "\n",
    "\n",
    "for i in mdepth:\n",
    "        model = DecisionTreeClassifier(max_depth=i)\n",
    "        model.fit(X_train_25,Y_train_25)\n",
    "        a1=model.score(X_train_25,Y_train_25)\n",
    "        a2=model.score(X_test,Y_test)\n",
    "        TrainingError_25.append(1-a1)\n",
    "        TestingError_25.append(1-a2)\n",
    "\n",
    "#train with 100 instances from each class\n",
    "\n",
    "for i in mdepth:\n",
    "        model = DecisionTreeClassifier(max_depth=i)\n",
    "        model.fit(X_train_100,Y_train_100)\n",
    "        y_pred = model.predict(X_train_100)\n",
    "        y_pred1= model.predict(X_test)\n",
    "        x1=accuracy_score(Y_train_100,y_pred)\n",
    "        x2=accuracy_score(Y_test,y_pred1)\n",
    "        TrainingError_100.append(1-x1)\n",
    "        TestingError_100.append(1-x2)\n",
    "        temp = 'Max_Depth = '+str(i)\n",
    "        index.append(temp)\n",
    "\n",
    "columns = ['Training Error','Test Error']\n",
    "\n",
    "Error_list_25=[]\n",
    "Error_list_100=[]\n",
    "for i in range(len(TrainingError_25)):\n",
    "    Error_list_25.append([TrainingError_25[i],TestingError_25[i]])\n",
    "    Error_list_100.append([TrainingError_100[i],TestingError_100[i]] )\n",
    "    \n",
    "print(\"Results with 25 instances\")   \n",
    "df_train_error_25 = pd.DataFrame(Error_list_25,columns=columns,index=index)\n",
    "print(df_train_error_25.head(20)) \n",
    "\n",
    "print()\n",
    "print(\"Results with 100 instances\")   \n",
    "df_train_error_100 = pd.DataFrame(Error_list_100,columns=columns,index=index)\n",
    "print(df_train_error_100.head(20))\n",
    "\n",
    "#Plotting the Graph showing how training and testing errors vary for number of instances\n",
    "plt.plot(mdepth,TestingError_25,label='Testing error for 25 instances')\n",
    "plt.plot(mdepth,TestingError_100,label='Testing error for 100 instances')\n",
    "plt.legend()\n",
    "plt.xlabel(' Max Depth')\n",
    "plt.ylabel(' Error Rate')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939091b",
   "metadata": {},
   "source": [
    "Plotting the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec80fafb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.externals.six'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-36654c2e5cf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.externals.six'"
     ]
    }
   ],
   "source": [
    "train_data = (pd.read_csv(r'C:\\Users\\gangareddy\\Documents\\GitHub\\MLprojects\\Assignment3\\optdigits.tra', sep=\",\",header=None))\n",
    "train_data = train_data.iloc[:, :-1]\n",
    "train_data.columns\n",
    "\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = train_data.columns,class_names=['0','1','2','3','4',\n",
    "                                                                                         '5','6','7','8','9'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('optdigits.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71769af",
   "metadata": {},
   "source": [
    "Q3:Repeat Q1 using XGBoost and LightGBM algorithms. Experiment with at least 5 different parameter settings to see their effect on training and test errors. How do best parameters change as the #training instances change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af9f9ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ XGBOOST ALGORITHM *************\n",
      "\n",
      "For 25 random instances\n",
      "\n",
      "[13:03:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 25 random instances using SET1parameters  0.0\n",
      "The testing error of 25 random instances using SET1 parameters  0.12020033388981632\n",
      "[13:04:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 25 random instances using SET2parameters  0.0\n",
      "The testing error of 25 random instances using SET2 parameters  0.14134668892598778\n",
      "[13:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 25 random instances using SET3parameters  0.0\n",
      "The testing error of 25 random instances using SET3 parameters  0.15303283249860877\n",
      "[13:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 25 random instances using SET4parameters  0.0040000000000000036\n",
      "The testing error of 25 random instances using SET4 parameters  0.15804117974401777\n",
      "[13:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 25 random instances using SET5parameters  0.01200000000000001\n",
      "The testing error of 25 random instances using SET5 parameters  0.1652754590984975\n",
      "\n",
      "For 100 random instances\n",
      "\n",
      "[13:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 100 random instances using SET1parameters  0.0050000000000000044\n",
      "The testing error of 100 random instances using SET1 parameters  0.0639955481357819\n",
      "[13:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 100 random instances using SET2parameters  0.0\n",
      "The testing error of 100 random instances using SET2 parameters  0.05954368391764053\n",
      "[13:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 100 random instances using SET3parameters  0.0\n",
      "The testing error of 100 random instances using SET3 parameters  0.06288258208124653\n",
      "[13:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 100 random instances using SET4parameters  0.0\n",
      "The testing error of 100 random instances using SET4 parameters  0.06677796327212016\n",
      "[13:04:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The training error of 100 random instances using SET5parameters  0.0010000000000000009\n",
      "The testing error of 100 random instances using SET5 parameters  0.07512520868113526\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST\n",
    "print(\"************ XGBOOST ALGORITHM *************\")\n",
    "\n",
    "print()\n",
    "print(\"For 25 random instances\")\n",
    "print()\n",
    "learning_rate= [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] \n",
    "max_depth= [3, 4, 5, 6, 8, 10, 12, 15]\n",
    "min_child_weight =[1, 3, 4, 5,7]\n",
    " #The value should be less than 1\n",
    "gamma = [0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    " #The value should be less than 1\n",
    "colsample_bytree = [0.3,0.4,0.5,0.6,0.7]\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(1,6,1):\n",
    "    xgb = XGBClassifier(learning_rate=learning_rate[i-1],max_depth=max_depth[i-1],min_child_weight=min_child_weight[i-1],gamma=gamma[i-1],colsample_bytree=colsample_bytree[i-1])\n",
    "    xgb.fit(X_train_25,Y_train_25)\n",
    "    print(\"The training error of 25 random instances using SET\"+str(i)+\"parameters \",1-xgb.score(X_train_25,Y_train_25))\n",
    "    print(\"The testing error of 25 random instances using SET\"+str(i)+\" parameters \",1-xgb.score(X_test,Y_test))\n",
    "print()\n",
    "print(\"For 100 random instances\")\n",
    "print()   \n",
    "for i in range(1,6,1):\n",
    "    xgb = XGBClassifier(learning_rate=learning_rate[i-1],max_depth=max_depth[i-1],min_child_weight=min_child_weight[i-1],colsample_bytree=colsample_bytree[i-1])\n",
    "    xgb.fit(X_train_100,Y_train_100)\n",
    "    print(\"The training error of 100 random instances using SET\"+str(i)+\"parameters \",1-xgb.score(X_train_100,Y_train_100))\n",
    "    print(\"The testing error of 100 random instances using SET\"+str(i)+\" parameters \",1-xgb.score(X_test,Y_test))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9c705a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ LIGHTBGM ALGORITHM *************\n",
      "\n",
      "For 25 random instances\n",
      "\n",
      "The training error of 25 random instances using SET1parameters  0.0\n",
      "The testing error of 25 random instances using SET1 parameters  0.12576516416249306\n",
      "The training error of 25 random instances using SET2parameters  0.0040000000000000036\n",
      "The testing error of 25 random instances using SET2 parameters  0.1419031719532554\n",
      "The training error of 25 random instances using SET3parameters  0.0040000000000000036\n",
      "The testing error of 25 random instances using SET3 parameters  0.1535893155258765\n",
      "The training error of 25 random instances using SET4parameters  0.01200000000000001\n",
      "The testing error of 25 random instances using SET4 parameters  0.16249304396215913\n",
      "The training error of 25 random instances using SET5parameters  0.016000000000000014\n",
      "The testing error of 25 random instances using SET5 parameters  0.18141346688925986\n",
      "******************************\n",
      "\n",
      "For 100 random instances\n",
      "\n",
      "The training error of 100 random instances using SET1parameters  0.0\n",
      "The testing error of 100 random instances using SET1 parameters  0.056761268781302165\n",
      "The training error of 100 random instances using SET2parameters  0.0\n",
      "The testing error of 100 random instances using SET2 parameters  0.06789092932665552\n",
      "The training error of 100 random instances using SET3parameters  0.0\n",
      "The testing error of 100 random instances using SET3 parameters  0.07234279354479689\n",
      "The training error of 100 random instances using SET4parameters  0.0010000000000000009\n",
      "The testing error of 100 random instances using SET4 parameters  0.07957707289927662\n",
      "The training error of 100 random instances using SET5parameters  0.008000000000000007\n",
      "The testing error of 100 random instances using SET5 parameters  0.09070673344462998\n"
     ]
    }
   ],
   "source": [
    "#LIGHTBGM\n",
    "print(\"************ LIGHTBGM ALGORITHM *************\")\n",
    "print()\n",
    "print(\"For 25 random instances\")\n",
    "print()\n",
    "learning_rate= [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] \n",
    "max_depth= [3, 4, 5, 6, 8, 10, 12, 15]\n",
    "min_child_weight =[1, 3, 4, 5,7]\n",
    " #The value should be less than 1\n",
    "reg_alpha = [0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    " #The value should be less than 1\n",
    "colsample_bytree = [0.3,0.4,0.5,0.6,0.7]\n",
    "\n",
    "for i in range(1,6,1):\n",
    "    lgb = LGBMClassifier(learning_rate=learning_rate[i-1],max_depth=max_depth[i-1],min_child_weight=min_child_weight[i-1],reg_alpha=reg_alpha[i-1],colsample_bytree=colsample_bytree[i-1])\n",
    "    lgb.fit(X_train_25,Y_train_25)\n",
    "    print(\"The training error of 25 random instances using SET\"+str(i)+\"parameters \",1-lgb.score(X_train_25,Y_train_25))\n",
    "    print(\"The testing error of 25 random instances using SET\"+str(i)+\" parameters \",1-lgb.score(X_test,Y_test))\n",
    "print(\"******************************\")    \n",
    "print()\n",
    "print(\"For 100 random instances\")\n",
    "print()\n",
    "for i in range(1,6,1):\n",
    "    lgb = LGBMClassifier(learning_rate=learning_rate[i-1],max_depth=max_depth[i-1],min_child_weight=min_child_weight[i-1],reg_alpha=reg_alpha[i-1],colsample_bytree=colsample_bytree[i-1])\n",
    "    lgb.fit(X_train_100,Y_train_100)\n",
    "    print(\"The training error of 100 random instances using SET\"+str(i)+\"parameters \",1-lgb.score(X_train_100,Y_train_100))\n",
    "    print(\"The testing error of 100 random instances using SET\"+str(i)+\" parameters \",1-lgb.score(X_test,Y_test)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09101884",
   "metadata": {},
   "source": [
    "Q4: Multilayer Perceptrons: classification Use library sklearn.neural_network.MLPClassifier. For the neural network (MLP) determine the value of the best hidden_layer_sizes (experiment with 1 and 2 hidden layers and 2, 5, 10 hidden units in each layer) that results in the best test error for each of the training data sets you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bcbd35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Printing results of 25 samples using Multilayer Perceptrons with 1 layer-----\n",
      "                   Training Error  Testing Error\n",
      "Hidden Units = 2            0.688       0.790762\n",
      "Hidden Units = 5            0.676       0.741792\n",
      "Hidden Units = 10           0.764       0.786311\n",
      "\n",
      "-----Printing results of 100 samples using Multilayer Perceptrons with 1 layer-----\n",
      "                   Training Error  Testing Error\n",
      "Hidden Units = 2            0.565       0.626043\n",
      "Hidden Units = 5            0.621       0.705064\n",
      "Hidden Units = 10           0.687       0.736227\n",
      "\n",
      "-----Printing results of 25 samples using Multilayer Perceptrons with 2 layers-----\n",
      "                   Training Error  Testing Error\n",
      "Hidden Units = 2            0.560       0.661658\n",
      "Hidden Units = 5            0.008       0.263773\n",
      "Hidden Units = 10           0.000       0.173623\n",
      "\n",
      "-----Printing results of 100 samples using Multilayer Perceptrons with 2 layers-----\n",
      "                   Training Error  Testing Error\n",
      "Hidden Units = 2            0.702       0.727323\n",
      "Hidden Units = 5            0.017       0.148024\n",
      "Hidden Units = 10           0.000       0.094602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# experiment with 1 and 2 hidden layers and 2, 5, 10 hidden units in each layer\n",
    "layers = [1,2]\n",
    "hidden_units = [2,5,10]\n",
    "trainError_25_layer1 = []\n",
    "testError_25_layer1 =[]\n",
    "trainError_100_layer1 = []\n",
    "testError_100_layer1 =[]\n",
    "\n",
    "trainError_25_layer2 = []\n",
    "testError_25_layer2 =[]\n",
    "trainError_100_layer2 = []\n",
    "testError_100_layer2 =[]\n",
    "index = []\n",
    "columns = ['Training Error','Testing Error']\n",
    "\n",
    "# for layer 1\n",
    "layers = 1\n",
    "for units in hidden_units:\n",
    "\n",
    "        clf1 = MLPClassifier( alpha=1e-5,max_iter=10000, hidden_layer_sizes=(units,layers), random_state=1)\n",
    "        clf1.fit(X_train_25, Y_train_25)\n",
    "        trainError_25_layer1.append(1 - clf1.score((X_train_25),(Y_train_25)))\n",
    "        testError_25_layer1.append(1 - clf1.score(X_test,Y_test))\n",
    "        \n",
    "        clf2 = MLPClassifier(alpha=1e-5, max_iter=10000,hidden_layer_sizes=(units,layers), random_state=1)\n",
    "        clf2.fit(X_train_100, Y_train_100)\n",
    "        trainError_100_layer1.append(1 - clf2.score((X_train_100),(Y_train_100)))\n",
    "        testError_100_layer1.append(1 - clf2.score(X_test,Y_test))\n",
    "        index.append('Hidden Units = '+str(units))\n",
    "\n",
    "# for layers 2\n",
    "layers = 2\n",
    "for units in hidden_units:\n",
    "\n",
    "        clf1 = MLPClassifier(alpha=1e-5, max_iter=10000, hidden_layer_sizes=(units,units), random_state=1)\n",
    "        clf1.fit(X_train_25, Y_train_25)\n",
    "        trainError_25_layer2.append(1 - clf1.score((X_train_25),(Y_train_25)))\n",
    "        testError_25_layer2.append(1 - clf1.score(X_test,Y_test))\n",
    "        \n",
    "        clf2 = MLPClassifier(alpha=1e-5, max_iter=10000, hidden_layer_sizes=(units,units), random_state=1)\n",
    "        clf2.fit(X_train_100, Y_train_100)\n",
    "        trainError_100_layer2.append(1 - clf2.score((X_train_100),(Y_train_100)))\n",
    "        testError_100_layer2.append(1 - clf2.score(X_test,Y_test))\n",
    "        \n",
    "\n",
    "Error_list_25=[]\n",
    "Error_list_100=[]\n",
    "Error_list2_25=[]\n",
    "Error_list2_100=[]\n",
    "for i in range(len(trainError_25_layer1)):\n",
    "    Error_list_25.append([trainError_25_layer1[i],testError_25_layer1[i]])\n",
    "    Error_list_100.append([trainError_100_layer1[i],testError_100_layer1[i]] )\n",
    "    \n",
    "    Error_list2_25.append([trainError_25_layer2[i],testError_25_layer2[i]])\n",
    "    Error_list2_100.append([trainError_100_layer2[i],testError_100_layer2[i]] )\n",
    "\n",
    "print(\"-----Printing results of 25 samples using Multilayer Perceptrons with 1 layer-----\")   \n",
    "df_train_error_25 = pd.DataFrame(Error_list_25,columns=columns,index=index)\n",
    "print(df_train_error_25.head(20))\n",
    "print()\n",
    "print(\"-----Printing results of 100 samples using Multilayer Perceptrons with 1 layer-----\")   \n",
    "df_train_error_100 = pd.DataFrame(Error_list_100,columns=columns,index=index)\n",
    "print(df_train_error_100.head(20))\n",
    "print()\n",
    "print(\"-----Printing results of 25 samples using Multilayer Perceptrons with 2 layers-----\")   \n",
    "df2_train_error_25 = pd.DataFrame(Error_list2_25,columns=columns,index=index)\n",
    "print(df2_train_error_25.head(20))\n",
    "print()\n",
    "print(\"-----Printing results of 100 samples using Multilayer Perceptrons with 2 layers-----\")   \n",
    "df2_train_error_100 = pd.DataFrame(Error_list2_100,columns=columns,index=index)\n",
    "print(df2_train_error_100.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0c693",
   "metadata": {},
   "source": [
    "\n",
    "Q5: Regression for digit completion: regression\n",
    "Use library sklearn.neural_network.MLPRegressor\n",
    "Using only the data for class 6 and class 9 in X100 for training,  use the first 48 features as inputs and predict the next 16 features,  i.e. create a neural network with 16 outputs. \n",
    "Report the test error (use only the instances from classes 6 and 9).\n",
    "Which pixels are easier to predict?\n",
    "(Clarification, each of your models will have the same set of features, namely features 1…48.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d813e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating given dataset with class 6 and class 9 and 48 features\n",
    "X_class69 = X100_train[X100_train[64] == 6]\n",
    "X_class69.append(X100_train[X100_train[64] == 9])\n",
    "# first 48 features from train data set with only 6 and 9 classes\n",
    "X_class69_48 = X_class69.iloc[:,0:48]\n",
    "# remaining 16 features from train data\n",
    "X_class69_16 = X_class69.iloc[:,48:64]\n",
    "\n",
    "X_test_69 = test_data[test_data[64] == 6]\n",
    "X_test_69.append(test_data[test_data[64] ==9])\n",
    "# remaining 16 features from test data\n",
    "Y_test_69_16 = X_test_69.columns[48:64]\n",
    "# first 48 features from test data set with only 6 and 9 classes\n",
    "X_test_69_48 = X_test_69.iloc[:,0:48]\n",
    "# classification column of training data\n",
    "Y_class69 = X_class69.iloc[:,64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c459a0a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Finding error for each feature from 49 to 64----\n",
      "\n",
      "Feature:   49\n",
      "Error value:  0.8648128665833489\n",
      "Feature:   50\n",
      "Error value:  2.3723172749558197\n",
      "Feature:   51\n",
      "Error value:  2.5799379099886544\n",
      "Feature:   52\n",
      "Error value:  3.6775639926568977\n",
      "Feature:   53\n",
      "Error value:  3.4750750074808985\n",
      "Feature:   54\n",
      "Error value:  2.6884667656834638\n",
      "Feature:   55\n",
      "Error value:  1.1916341841226659\n",
      "Feature:   56\n",
      "Error value:  0.631866705451999\n",
      "Feature:   57\n",
      "Error value:  0.6291280102479846\n",
      "Feature:   58\n",
      "Error value:  1.2333314776294684\n",
      "Feature:   59\n",
      "Error value:  2.371978252739448\n",
      "Feature:   60\n",
      "Error value:  1.93879730543843\n",
      "Feature:   61\n",
      "Error value:  3.3205065724721514\n",
      "Feature:   62\n",
      "Error value:  4.022334389964018\n",
      "Feature:   63\n",
      "Error value:  0.9047330814038422\n",
      "Feature:   64\n",
      "Error value:  0.5421517409977663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "regr = MLPRegressor(random_state=1, max_iter=200)\n",
    "\n",
    "print('\\n----Finding error for each feature from 49 to 64----\\n')\n",
    "original=[]\n",
    "predicted=[]\n",
    "for k in range(49, 65):\n",
    "    y_value = X_class69[k]\n",
    "    testing_for_y = X_test_69[k]\n",
    "    original.append(testing_for_y)\n",
    "    regr.fit(X_class69_48, y_value)\n",
    "    predicted_y = regr.predict(X_test_69_48.values)\n",
    "    predicted.append(predicted_y)\n",
    "    print('Feature:  ',k)   \n",
    "    print('Error value: ',math.sqrt(mean_squared_error(testing_for_y, predicted_y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66cb44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
