{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/uciml/pima-indians-diabetes-database - Download the indian diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Import relevant commands for numpy, pandas, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn import cluster\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Using the appropriate pandas function, read the diabetes.csv into a dataframe. Pay good attention to the necessary arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              5       95             72             33        0  37.7   \n",
      "1              0      131              0              0        0  43.2   \n",
      "2              2      112             66             22        0  25.0   \n",
      "3              3      113             44             13        0  22.4   \n",
      "4              2       74              0              0        0   0.0   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           13      126             90              0        0  43.4   \n",
      "764            4      129             86             20      270  35.1   \n",
      "765            1       79             75             30        0  32.0   \n",
      "766            1        0             48             20        0  24.7   \n",
      "767            7       62             78              0        0  32.6   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.370   27        0  \n",
      "1                       0.270   26        1  \n",
      "2                       0.307   24        0  \n",
      "3                       0.140   22        0  \n",
      "4                       0.102   22        0  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.583   42        1  \n",
      "764                     0.231   23        0  \n",
      "765                     0.396   22        0  \n",
      "766                     0.140   22        0  \n",
      "767                     0.391   41        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv('diabetes.csv', sep=\",\")\n",
    "print(data)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.use naivebayes, logistic regression and 3-nn classifiers (library) to train on the training sets and \n",
    "compute training and validation errors for each fold (see the diabetes_10fold_train_val.zip file, XT01...XT10: training sets, XV01....XV10: corresponding validation sets). The target label is Outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for training set 01: \n",
      "NB:  0.21052631578947367\n",
      "LR:  0.23684210526315785\n",
      "NN:  0.25\n",
      "Error for training set 02: \n",
      "NB:  0.2857142857142857\n",
      "LR:  0.2597402597402597\n",
      "NN:  0.4155844155844156\n",
      "Error for training set 03: \n",
      "NB:  0.2987012987012987\n",
      "LR:  0.2727272727272727\n",
      "NN:  0.2987012987012987\n",
      "Error for training set 04: \n",
      "NB:  0.16883116883116878\n",
      "LR:  0.16883116883116878\n",
      "NN:  0.16883116883116878\n",
      "Error for training set 05: \n",
      "NB:  0.22077922077922074\n",
      "LR:  0.18181818181818177\n",
      "NN:  0.24675324675324672\n",
      "Error for training set 06: \n",
      "NB:  0.2597402597402597\n",
      "LR:  0.22077922077922074\n",
      "NN:  0.35064935064935066\n",
      "Error for training set 07: \n",
      "NB:  0.22077922077922074\n",
      "LR:  0.23376623376623373\n",
      "NN:  0.2597402597402597\n",
      "Error for training set 08: \n",
      "NB:  0.2727272727272727\n",
      "LR:  0.2597402597402597\n",
      "NN:  0.33766233766233766\n",
      "Error for training set 09: \n",
      "NB:  0.18181818181818177\n",
      "LR:  0.19480519480519476\n",
      "NN:  0.3246753246753247\n",
      "Error for training set 10: \n",
      "NB:  0.3026315789473685\n",
      "LR:  0.2894736842105263\n",
      "NN:  0.368421052631579\n",
      "Final NB error:  0.24222488038277512\n",
      "Final LR error:  0.23185235816814762\n",
      "Final NN error:  0.30210184552289815\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Create a logistic regression classifier\n",
    "lrclassifier = LogisticRegression(random_state=0, max_iter=1000)\n",
    "\n",
    "#Create a knn classifier\n",
    "knn   = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#find the mean at the end\n",
    "knn_mean=[]\n",
    "log_mean=[]\n",
    "naive_mean=[]\n",
    "\n",
    "# create a list to store the file numbers\n",
    "file_number = ['01','02','03','04','05','06','07','08','09','10']\n",
    "# loop here to calculate the error for each training set\n",
    "for i in file_number:\n",
    "    trainingSet = '/Users/STSC/Desktop/MLprojects-main/diabetes_10fold_train_val/XT'+i+'.csv'\n",
    "    XT = read_csv(trainingSet, sep=\",\")\n",
    "    validationSet = '/Users/STSC\\Desktop/MLprojects-main/diabetes_10fold_train_val/XV'+i+'.csv'\n",
    "    VT = read_csv(validationSet, sep=\",\")\n",
    "    \n",
    "    # all features in x train\n",
    "    X_train =  XT.iloc[:,1:8]\n",
    "    # outcome or label in Y train\n",
    "    Y_train = XT.iloc[:,8]\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    \n",
    "    logistic = lrclassifier.fit(X_train, Y_train)\n",
    "    \n",
    "    fit   = knn.fit(X_train, Y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    VT_features =  VT.iloc[:,1:8]\n",
    "    y_pred_nb = gnb.predict(VT_features)\n",
    "    y_pred_nn = fit.predict(VT_features)\n",
    "    y_pred_lr = logistic.predict(VT_features)\n",
    "    VT_label =  VT.iloc[:,8]\n",
    "    accuracy_nb = metrics.accuracy_score(VT_label, y_pred_nb)\n",
    "    accuracy_lr = metrics.accuracy_score(VT_label, y_pred_lr)\n",
    "    accuracy_nn = metrics.accuracy_score(VT_label, y_pred_nn)\n",
    "\n",
    "    #mean_nb = mean_nb+ (1- accuracy_nb)\n",
    "    #mean_lr = mean_nb+ (1- accuracy_lr)\n",
    "    #mean_nn = mean_nb+ (1- accuracy_nn)\n",
    "    \n",
    "    naive_mean.append(1- accuracy_nb)\n",
    "    log_mean.append(1- accuracy_lr)\n",
    "    knn_mean.append(1- accuracy_nn)\n",
    "\n",
    "    # Model Accuracy and Error\n",
    "    print(\"Error for training set \"+ i+ \": \")\n",
    "    print(\"NB: \" ,1 - accuracy_nb)\n",
    "    print(\"LR: \"  ,1 - accuracy_lr)\n",
    "    print(\"NN: \"  ,1 - accuracy_nn)\n",
    "\n",
    "# calculating average error from 10 sets\n",
    "print(\"Final NB error: \",np.mean(naive_mean))\n",
    "print(\"Final LR error: \",np.mean(log_mean))\n",
    "print(\"Final NN error: \",np.mean(knn_mean))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9188499477356338\n"
     ]
    }
   ],
   "source": [
    "m=np.mean(naive_mean)\n",
    "S=np.std(naive_mean)\n",
    "k=10\n",
    "#T test\n",
    "Value=((k**0.5)*(m-0.2))/S\n",
    "print(Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2587263613579403\n"
     ]
    }
   ],
   "source": [
    "alpha=0.1\n",
    "df1=2\n",
    "df2=27\n",
    "df_total=29\n",
    "number_of_folds=10\n",
    "\n",
    "f_crit=2.51061\n",
    "\n",
    "\n",
    "total_Mean=(np.mean(log_mean)+np.mean(naive_mean)+np.mean(knn_mean))/3\n",
    "print(total_Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST 0.0028759435483632348\n",
      "SSW 0.0822252202774382\n",
      "F value 4.721816222796662\n"
     ]
    }
   ],
   "source": [
    "logreg_calc=[]\n",
    "logreg_ss=[]\n",
    "calc=(np.mean(log_mean)-total_Mean)**2\n",
    "for i in range(len(log_mean)):\n",
    "    #calc=(logistic_mean-total_Mean)**2\n",
    "    ss_within=(log_mean[i]-np.mean(log_mean))**2\n",
    "    #logreg_calc.append(calc)\n",
    "    logreg_ss.append(ss_within)\n",
    "sst_logreg=calc\n",
    "logreg_ssw=sum(logreg_ss)\n",
    "\n",
    "naive_calc=[]\n",
    "naive_ss=[]\n",
    "calc=(np.mean(naive_mean)-total_Mean)**2\n",
    "for i in range(len(naive_mean)):\n",
    "   \n",
    "    ss_within=(naive_mean[i]-np.mean(naive_mean))**2\n",
    "    \n",
    "    naive_ss.append(ss_within)\n",
    "sst_naive=calc\n",
    "naive_ssw=sum(naive_ss)\n",
    "\n",
    "knn_calc=[]\n",
    "knn_ss=[]\n",
    "calc=(np.mean(knn_mean)-total_Mean)**2\n",
    "for i in range(len(knn_mean)):\n",
    "   # calc=(knn_mean-total_Mean)**2\n",
    "    ss_within=(knn_mean[i]-np.mean(knn_mean))**2\n",
    "    #knn_calc.append(calc)\n",
    "    knn_ss.append(ss_within)\n",
    "sst_knn=calc\n",
    "knn_ssw=sum(knn_ss)\n",
    "total_sst=sst_logreg+sst_naive+sst_knn\n",
    "total_ssw=logreg_ssw+naive_ssw+knn_ssw\n",
    "print('SST',total_sst)\n",
    "print('SSW',total_ssw)\n",
    "\n",
    "ssb_total=(np.mean(log_mean)-total_Mean)**2+(np.mean(naive_mean)-total_Mean)**2+(np.mean(knn_mean)-total_Mean)**2\n",
    "ms_between=k*ssb_total/df1\n",
    "ms_within=total_ssw/df2\n",
    "f_value=ms_between/ms_within\n",
    "print('F value',f_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.is the error of naive bayes <0.2 with confidence 0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.have  naive bayes and knn the same error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.do the three classifiers have different errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
